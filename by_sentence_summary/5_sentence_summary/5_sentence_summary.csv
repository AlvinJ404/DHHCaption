original_sentence,summary,level
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The unknown creator is gone but made a valuable innovation. This technology inspires solving payment and banking issues. This class, however, is on a different topic.",7
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The unknown creator has vanished but made a valuable technology, inspiring solutions beyond payments. This class covers something else.",8
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.",The unknown creator made valuable technology. This class covers a different subject.,9
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.",We capture emotional information with an image. Understanding emotions is vital for our social interactions. We guess how others feel to adapt communication.,9
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","Emotional data is captured by one image, helping us recognize others' feelings. It's crucial for social interactions and adapting our communication.",8
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.",We capture emotions with one image. This ability is vital for social interactions and helps us adapt communication to how others feel.,7
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","One image captures emotional information. Recognizing emotions aids social interactions, adapting how we communicate.",6
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","Emotional info from one image helps us recognize feelings, crucial for social interaction and how we communicate.",5
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","One image captures emotional details, aiding in recognizing emotions for social interaction and adjusting communication.",4
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","Emotional information is captured from an image. This helps us recognize emotions, very useful in social interactions to adapt communication.",3
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.",Recognizing emotions from one image provides emotional information critical for social interactions and communication adjustments.,2
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.",Emotional recognition from an image gives information crucial for social interaction and communication adjustment.,1
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Identifying people's needs and predicting their reactions is crucial. Emotions significantly impact our cognitive processes, such as attention, memory, and learning. Given the importance of emotions, envisioning future AI becomes pertinent. How many have seen any of these movies?",1
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","It's crucial to detect people's needs and predict their reactions. Emotions influence cognition, affecting attention, memory, and learning. How many have seen these movies?",2
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Detecting needs and predicting reactions are essential. Emotions affect attention, memory, and learning. Have you seen these movies?",3
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","It is important to detect needs and predict reactions. Emotions affect attention, memory, and learning. How many have seen these movies?",4
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Detecting needs and predicting reactions is vital. Emotions affect thinking processes, attention, memory, and learning. Seen these movies?",5
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","It's vital to understand needs and predict reactions. Emotions influence thinking, attention, memory, and learning. Seen these movies?",6
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Know needs, predict reactions. Emotions affect thinking, attention, learning. Seen the movies?",8
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Know needs, predict reactions. Emotions affect thinking, memory, learning. Seen the movies?",9
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|","Most have seen at least one future machine movie with emotional intelligence. Emotions are complex, hard to understand, and it's difficult to measure how others feel.|",1
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",You know future machines in movies have emotional intelligence. Emotions are complex and it's tough to understand how others feel.|,2
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|","Machines in movies have emotional intelligence, but emotions are complex and hard to understand.|",3
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Future machines in movies have emotional intelligence. Emotions are tough to understand.|,4
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Machines in future movies have emotional intelligence. Emotions are complex.|,5
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Machines in future movies are emotionally intelligent. Understanding emotions is hard.|,6
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Movies feature future machines with emotional intelligence. Emotions are tricky.|,7
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Future movies show machines with emotions. Emotions are complex.|,8
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Future movies show machines with emotional intelligence.|,9
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Understanding emotions is complex for machines because emotions cause many body changes. When nervous, our heart and respiration rates go up, we sweat, and our facial expressions, gaze, pupils, blood pressure, postures, and gestures all change.",1
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines find it hard to understand emotions because of the many changes in the body when we're nervous, such as heart and respiration rate increases, sweating, and changes in facial expressions, gaze, pupils, blood pressure, and gestures.",2
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines can't easily recognize emotions because body signs change a lot when we're nervous, including heart and breath rate, sweating, facial expressions, gaze, pupils, blood pressure, and gestures.",3
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines struggle with understanding emotions because body signs change with feelings, like heart and breath rate, sweating, gaze, facial expressions, pupils, blood pressure, and gestures.",4
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines find emotions hard to understand because body signs like heart rate, breath rate, sweating, facial expressions, gaze, pupils, blood pressure, and gestures change.",5
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines struggle because our emotions cause many body changes, like heart rate, breath rate, sweat, facial expressions, gaze, pupils, blood pressure, and gestures.",6
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines find emotions hard to understand because body changes like heart rate, breath rate, sweating, expressions, gaze, pupils, blood pressure, and gestures differ.",7
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines struggle to grasp emotions because many body changes occur, like heart rate, breath rate, sweat, expressions, gaze, pupils, blood pressure, and gestures.",8
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines struggle with emotions because body signs like heart rate, breath rate, sweat, expressions, gaze, pupils, blood pressure, and gestures change.",9
"Our voice can change as well, the way we write, the way we type in our phones, for instance.",The way we speak and write can change.,9
So there are a lot of signals that change with our emotions.,Many signals change with our emotions.,9
So what we can do is all of these signals can be captured with different types of sensors.,Many sensors can capture these signals.,9
"And then we capture these signals, and if we have data, label data with emotions,",We capture signals and label data with emotions.,8
What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information.,We can find patterns in signals and develop machine learning to recognize emotions.,6
The same way we process other type of information.,Just like we process other information.,8
"Our voice can change as well, the way we write, the way we type in our phones, for instance.",Our voice and writing change with emotions.,7
So there are a lot of signals that change with our emotions.,Emotions change many signals in us.,7
So what we can do is all of these signals can be captured with different types of sensors.,Different sensors can capture these signals.,8
"And then we capture these signals, and if we have data, label data with emotions,","We capture signals, label them with emotions.",7
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?","Initially, I will discuss how we capture emotional data, starting with my expertise in visual modality and cameras. What has been done to recognize emotions through visual data?",1
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?","I will start with vision modality to capture emotional information. With cameras, how has emotion recognition been achieved?",2
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",We will look at capturing emotions with vision modality. How have cameras been used for emotion recognition so far?,4
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?","Let's examine how to capture emotions using vision modality, especially with cameras. How has emotion recognition been approached?",5
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",I will discuss how we capture emotional data using visual modality and cameras. What's been done for recognizing emotions?,7
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",I'll discuss capturing emotional information with visual modality. How do cameras recognize emotions?,8
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",Let's focus on how we capture emotions with cameras. What has been done in this area?,9
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",How do we capture emotions with cameras? What has been done in this field?,1
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",The primary method in computer vision to recognize emotions is facial expression.,9
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",The main research theme in computer vision for emotion recognition is facial expressions.,8
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",The most frequent technique to recognize emotions in computer vision is facial expressions.,7
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Facial expression analysis is widely used in computer vision research for emotion recognition.,6
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Facial expressions are predominant in computer vision research for recognizing emotions.,5
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Recognizing emotions through facial expressions is a key topic in computer vision research.,4
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Emotion recognition via facial expressions is a significant area of computer vision research.,3
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Computer vision research significantly focuses on recognizing emotions through facial expressions.,2
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Recognizing emotions through facial expressions has been a major unsolved problem in computer vision.,1
"So now after 10 years, we have these softwares that work very well in recognizing some of the key points on your face, tracking these key points, and doing some matching between the emotions, so the expressions that are observed and the possible emotions that they are expressing.","After a decade, software effectively identifies facial key points and matches them to possible emotions.",1
"This software works very well, so it's very well at detecting the patterns, it's very while detecting the key points, it's complicated to associate the correct emotion to an expression, a phase expression, but it works pretty well in some applications.",This software detects patterns and key points well but struggles to accurately match expressions to emotions.,3
"It's being used for test users, for instance, but the problem of this software is that it does not work in the wild.",It is used for test users but fails to work in uncontrolled environments.,4
So we would like to have machines that can recognize emotions in any condition.,We want machines that can detect emotions in all conditions.,5
"So now after 10 years, we have these softwares that work very well in recognizing some of the key points on your face, tracking these key points, and doing some matching between the emotions, so the expressions that are observed and the possible emotions that they are expressing.",Advanced software now accurately tracks facial points and matches them to emotions.,6
"This software works very well, so it's very well at detecting the patterns, it's very while detecting the key points, it's complicated to associate the correct emotion to an expression, a phase expression, but it works pretty well in some applications.",The software detects patterns well but struggles to match expressions with emotions.,8
"It's being used for test users, for instance, but the problem of this software is that it does not work in the wild.","Used in tests, the software fails in uncontrolled settings.",9
So we would like to have machines that can recognize emotions in any condition.,We want machines to detect emotions everywhere.,1
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","The software detects the face, key points, smile, and attention of the woman. It shows happiness but fails with him.",6
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.","We have another face example. The software detects surprise with an open mouth, a typical expression.",1
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",The software detects a face showing surprise with an open mouth; a common expression.,2
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Another face example shows surprise detected by the software.,3
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.","The software sees a face that shows surprise, mouth open.",4
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.","Software detects a face showing surprise, mouth open.",5
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Face showing surprise is detected by software.,6
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Software detects surprise on face.,7
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Software sees a surprised face.,8
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Software sees surprise.,9
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","Context shows the facial expression is not surprising and is related to the action being performed, not emotion. Some expressions aren't emotional but functional, like those while talking.",9
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","The context shows the surprising expression is about actions, not emotions. Some facial expressions link to actions like talking, not emotions.",3
And another difficulty is giving the correct emotional meaning to an isolated facial expression.,Assigning the right emotion to a facial expression is tough.,9
"So I'm going to show you some examples of experiments that were performed by psychologists that were studying what's the level of agreement in giving an emotional label to a specific facial expression, like here.",Here are experiments by psychologists on agreement in labeling emotions in facial expressions.,4
"So here we see clearly a facial expression, but if I ask you, what's this facial expression communicating? Well, you might think maybe anger, maybe contempt, this gas fear.|","What emotion does this facial expression show? Anger, contempt, or fear?",8
"So usually people agree that this is a negative, valence emotion, but it's not clear what category.|","People generally agree it's a negative emotion, but the exact category is unclear.",6
And another difficulty is giving the correct emotional meaning to an isolated facial expression.|,Another challenge is identifying the correct emotion in a single facial expression.,5
"So I'm going to show you some examples of experiments that were performed by psychologists that were studying what's the level of agreement in giving an emotional label to a specific facial expression, like here.|",I will show experiments by psychologists on agreement in labeling a facial expression.,7
"So here we see clearly a facial expression, but if I ask you, what's this facial expression communicating? Well, you might think maybe anger, maybe contempt, this gas fear.|","Here is a facial expression; does it show anger, contempt, or fear?",8
"So usually people agree that this is a negative, valence emotion, but it's not clear what category.|","People typically agree it shows a negative emotion, though the category is fuzzy.",6
And another difficulty is giving the correct emotional meaning to an isolated facial expression.|,It is hard to give the right emotional meaning to a single facial expression.,5
"So I'm going to show you some examples of experiments that were performed by psychologists that were studying what's the level of agreement in giving an emotional label to a specific facial expression, like here.|",Here are psychologist experiments on agreement in emotional labeling of expressions.,4
"The thing is that if I give you some context suddenly, we probably will agree that this is disgust and this is what happens.","With sudden context, we likely agree it is disgust.",5
People agree here that the face is disgust.,People agree the face shows disgust.,7
"But if you give you a different context, then people strongly agree that this is anger.","In a different context, people agree it is anger.",6
So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts.,They have many examples and do experiments using the same facial expressions in different contexts.,4
And they realize that the context strongly influences the way we perceive emotions.,They find that context strongly affects how we perceive emotions.,6
"So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face.","This project, started in Barcelona with MIT, aims to make machines understand emotions not just from faces but also from context.",9
"We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person.",Understanding the scene context is critical for recognizing a person's emotions.,8
And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.,Analyzing context provides deeper insights about emotions.,8
"So maybe with the expression, you can say something about basic emotions, but there are some secondary emotions or social emotions that are very interesting that if you don't see the context, you cannot say anything about them.","Facial expressions reveal basic emotions, but context is needed for secondary or social emotions.",6
"Like here, once you see the context, you might say that this person is feeling confident.","Seeing context can reveal emotions, like confidence.",9
"And the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face.","To improve emotion recognition, machines need the context, not just facial data.",7
"In particularly we are working in the scene context, in the situation of the person.",We're focusing on the person's situational context.,8
The interesting thing of working in this type of context is that suddenly you can say much more about the emotion.,Context allows for a richer understanding of emotion.,8
"For developing machines that accurately recognize emotions, we can just rely on the face.",Reliable emotion recognition requires more than just facial data.,9
"There are some secondary emotions or social emotions that are very interesting that if you don't see the context, you cannot say anything about them.","Without context, secondary and social emotions cannot be understood.",8
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Defining confidence involves feeling sure, convinced of favorable outcomes, encouraged, or proud. This forms the basis of our emotion recognition project. We aim to use images for emotion recognition, considering the context, not just facial features. This is a computer vision project, and deep learning is the most effective approach currently. So we plan to use deep learning to tackle this issue.",1
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence is the feeling of certainty or pride in favorable outcomes. This guides our emotion recognition project, focusing on images to detect emotions, considering both face and context. As a computer vision project, deep learning is our chosen approach to model this problem.",2
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence means feeling sure, proud, or encouraged about favorable outcomes. Our emotion recognition project focuses on using images to detect emotions, considering faces and context. As a computer vision project, we use deep learning to solve this problem.",3
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence, a sense of assurance and pride in positive outcomes, is the basis for our emotion recognition project. We use images to detect emotions, considering faces and context. As a computer vision project, we utilize deep learning to solve this issue.",4
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence is assurance and pride in positive outcomes, guiding our emotion recognition project. We analyze images to detect emotions using both face and context. This computer vision project uses deep learning to address the task.",5
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence is the feeling of assurance and pride. Our project aims to detect emotions in images, considering face and context. This computer vision task uses deep learning.",6
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence is being sure and proud. The goal is to detect emotions in images, using faces and context. This project uses deep learning in computer vision.",7
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence means being sure and proud. The project detects emotions in images, considering face and context, using deep learning.",8
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.",Confidence is certainty and pride. We detect emotions in images using deep learning.,9
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","We lacked data, collected images, and made annotation tools.",9
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.",We collected images and made tools.,1
We had two different interfaces.,We had two interfaces.,9
This is the one of emotion categories.,This is one of the emotion categories.,8
And we have another one for continuous dimensions.,We also have one for continuous dimensions.,7
So there are different ways of representing emotions in a machine.,There are different ways to represent emotions in a machine.,6
We had two different interfaces.,Two different interfaces were available.,4
This is the one of emotion categories.,This pertains to emotion categories.,3
And we have another one for continuous dimensions.,Another interface is for continuous dimensions.,2
So there are different ways of representing emotions in a machine.,Emotions can be represented in a machine in different ways.,1
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common; emotional dimensions less so. Valence measures if feelings are positive or negative. Arousal indicates calmness or readiness to act, while dominance shows control or lack thereof.",9
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, emotional dimensions less so. Valence identifies positive or negative emotions. Arousal measures calmness or agitation, and dominance shows control or dominance.",7
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, emotional dimensions less known. Valence measures positive or negative emotions. Arousal assesses calmness or agitation. Dominance indicates control or domination.",6
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, emotional dimensions less so. Valence gauges if emotions are positive or negative, arousal measures calmness or agitation, and dominance shows control or domination.",5
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, emotional dimensions less familiar. Valence measures positive or negative feelings, arousal indicates calm or agitated states, and dominance shows if one feels controlled or in control.",4
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are frequent, emotional dimensions less known. Valence measures positive or negative, arousal measures calm or ready states, and dominance indicates controlled or in control feelings.",3
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, but emotional dimensions are less so. Valence gauges positive or negative feelings. Arousal measures calmness or agitation. Dominance assesses if one feels controlled or in control of the situation.",2
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are frequent, but emotional dimensions are not as popular. Valence measures whether feelings are positive or negative. Arousal measures calmness or agitation. Dominance evaluates if someone feels in control or dominated by the situation.",1
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","We collected demographics like gender and age of people in pictures using Amazon Mechanical Turk, creating a large data set.",5
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","Using Amazon Mechanical Turk, we collected demographics such as gender and age from pictures, creating a large data set.",6
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","We used Amazon Mechanical Turk to collect demographics such as gender and age from pictures, creating a big data set.",7
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.",We used Amazon Mechanical Turk to gather demographics like gender and age from pictures into a big data set.,8
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","Using Amazon Mechanical Turk, we gathered demographics like gender and age from photos to make a big data set.",9
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",The deep learning model developed by us is simple; it takes an image and knows the target person's location to recognize their emotion.,1
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.","We developed a baseline deep learning model. It is simple, with an image input and target person's location, to recognize emotions.",2
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",Our simple baseline deep learning model takes an image and identifies the target person to recognize their emotion.,3
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",The simple baseline deep learning model we developed uses images and target locations to recognize emotions.,4
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",We created a simple deep learning model to recognize emotions from an image of a target person.,5
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",We developed a simple model to recognize the target person's emotion from an image.,6
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",Our model recognizes emotions from the target person's image.,7
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",The simple model finds emotions in images.,8
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",The model detects emotions.,9
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",It spots emotions.,1
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We use a network to extract features from the person's bounding box. Another module extracts features from the whole image. We merge them with one layer to recognize balance, dominance, and emotions.",7
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We get features from the person's box using a network. Another module gets features from the whole image. We merge them with one layer to recognize balance, dominance, and emotions.",8
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We use a network to get features from the person's box. Another module gets features from the image. We merge them to recognize balance, dominance, and emotions.",9
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We get features from the person's box with a network. Another module gets features from the image. We merge them to recognize balance, dominance, and emotions.",1
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use a regression loss function as it modeled our data best. We obtained these results and these images. This image recognizes anticipation, excitement, engagement, and confidence. Another image shows recognition, pleasure, happiness, and affection.|",9
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression for our loss function based on our experiments which showed it models data best. These are the results and images we get, recognizing anticipation, excitement, engagement, and confidence in one case, and recognition, pleasure, happiness, and affection in another.|",8
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression as our loss function based on experiments that showed it models data best. These results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",7
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We selected a regression loss function because experiments showed it models data best. The results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",6
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression based on experiments showing it models data best. Results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",5
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We chose regression loss function as experiments showed it models data best. Results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",4
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression after experiments showed it models data best. Results show images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",3
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression because experiments showed it models data best. Results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",2
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression since experiments showed it models data best. Results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",1
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation.|",The system recognized happiness without seeing the face by extracting context and situational information.|,8
"Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output.|","For one person, emotions like pleasure, affection, and happiness were recognized, but for another, it was chaotic. This shows that the system uses both context and personal information.|",7
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation.|","The system recognized happiness even without seeing a face, by extracting context and situation.|",8
"Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output.|","Emotions like pleasure, affection, and happiness were recognized for one person but were chaotic for another, showing context and personal info are used.|",5
"So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context.|","The system's first attempt to recognize emotions using situational context and the person, not just the face, is not very successful.|",4
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation.|","The system recognized happiness without using facial information, relying on context and situation instead.|",7
"Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output.|","For one person, emotions of pleasure, affection, and happiness were recognized, but it was chaotic for another, showing both context and personal info are used.|",4
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","The Red House restaurant in Cambridge, Massachusetts, has reviews online that help patrons understand its offerings.|",9
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","In Cambridge, Massachusetts, the Red House restaurant has various reviews you can find online to learn about it.|",8
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","The Red House in Cambridge, MA has online reviews to help new visitors learn about it.|",7
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","Reviews of the Red House, located in Cambridge, Massachusetts, are available online for those who want to learn about it.|",6
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","You can find reviews of the Red House restaurant in Cambridge, Massachusetts, online to understand how it operates.|",4
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","To learn about the Red House restaurant in Cambridge, MA, you can search online for reviews and find out useful information.|",3
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","When visiting the Red House restaurant in Cambridge, Massachusetts, for the first time, you can look up reviews online to see how it operates.|",2
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","If you visit the Red House restaurant in Cambridge, MA, for the first time and wish to understand its operation, you can find reviews online.|",1
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","If you are visiting the Red House restaurant in Cambridge, Massachusetts for the first time and you want to know how the restaurant operates, you may search for online reviews for guidance.|",1
"So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.","It describes a delightful menu, great cocktails, and a relaxed atmosphere with locals and professors.",9
"Okay, so we read this type of reviews and from these reviews, we decide whether we want to go to the restaurant or not.",We read such reviews to decide on visiting the restaurant.,8
Somehow we capture the idea of whether this restaurant is good or not.,We determine if the restaurant is good or not from the review.,7
"But it is not saying, this is a good restaurant, go there or this is not a good restaurant, don't go there.",It does not explicitly say to go or not go to the restaurant.,6
Somehow we capture the idea of whether this restaurant is good or not.,We figure out if the restaurant is good or bad.,5
"So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.",It describes a pleasure with a good menu and atmosphere.,4
"Okay, so we read this type of reviews and from these reviews, we decide whether we want to go to the restaurant or not.",We read reviews to decide if we should visit.,3
"We read this type of reviews and from these reviews, we decide whether we want to go to the restaurant or not.",Reviews help us decide to go or not.,1
"It describes a delightful menu, great cocktails, and a relaxed atmosphere with locals and professors.","Reviews describe menu, cocktails, and atmosphere.",1
"So from this type of information, can you tell me if the person that wrote this text was feeling something positive or something negative about the restaurant?",Can you determine if the writer felt positive or negative about the restaurant from this information?,1
Is it positive?,Is it positive?,9
It's very clear.,It's very clear.,8
"For us, it's very easy to do.",It's quite simple for us.,7
So one thing that we can think is maybe we can develop algorithms that do the same.,Perhaps we can create algorithms to do this.,6
And they formulated the following problem.,They identified a problem.,9
"And when, so they have a deep learning architecture, you can actually, the code is available and they have also a demo online.",They have a deep learning model with code and an online demo.,7
"So if you enter the text I showed you before, you'll see this type of output.",Enter the text to see the output.,8
And they formulated the following problem.,They defined the problem.,8
"And when, so they have a deep learning architecture, you can actually, the code is available and they have also a demo online.",They use a deep learning model; code and demo are online.,6
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"This is effective, and similar models also work well for tech sentiment analysis.|",9
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,It works well. Similar models also analyze tech sentiment well.|,8
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,This model performs well. Other similar models also perform well in analyzing tech sentiment.|,7
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,This model works quite well. There are other similar models that are effective for tech sentiment analysis too.|,6
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"This model functions effectively for tech sentiment analysis, as do other similar models.|",5
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,This model and similar others work effectively for sentiment analysis in technology.|,4
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"For tech sentiment analysis, this model and other similar ones demonstrate effective performance.|",3
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"This model, along with others of its kind, proves to be quite effective in analyzing technological sentiment.|",2
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"This model exhibits a high degree of efficiency for tech sentiment analysis, and similarly, other models exhibit comparable effectiveness.|",1
