original_sentence,summary,level
"obvious is what is a cryptocurrency? So this word was kind of invented 10 years ago when, I don't know how many of you know the origin story of where Bitcoin came from, but basically a pseudonym on the internet dropped a paper and some open source code in a forum on an email list and said, hey, I have this idea for this thing called Bitcoin. It's kind of like electronic cash. Here's how I think it could work. And here is some code if you want to run it and become part of this peer-to-peer network.|","A pseudonym posted about Bitcoin, similar to electronic cash, with code for a peer-to-peer network 10 years ago in a forum.|",9
"obvious is what is a cryptocurrency? So this word was kind of invented 10 years ago when, I don't know how many of you know the origin story of where Bitcoin came from, but basically a pseudonym on the internet dropped a paper and some open source code in a forum on an email list and said, hey, I have this idea for this thing called Bitcoin. It's kind of like electronic cash. Here's how I think it could work. And here is some code if you want to run it and become part of this peer-to-peer network.|","A pseudonym shared Bitcoin, like electronic cash, with code for a network 10 years ago.|",8
"obvious is what is a cryptocurrency? So this word was kind of invented 10 years ago when, I don't know how many of you know the origin story of where Bitcoin came from, but basically a pseudonym on the internet dropped a paper and some open source code in a forum on an email list and said, hey, I have this idea for this thing called Bitcoin. It's kind of like electronic cash. Here's how I think it could work. And here is some code if you want to run it and become part of this peer-to-peer network.|","Bitcoin, which started 10 years ago, was introduced as electronic cash with some code.|",7
"obvious is what is a cryptocurrency? So this word was kind of invented 10 years ago when, I don't know how many of you know the origin story of where Bitcoin came from, but basically a pseudonym on the internet dropped a paper and some open source code in a forum on an email list and said, hey, I have this idea for this thing called Bitcoin. It's kind of like electronic cash. Here's how I think it could work. And here is some code if you want to run it and become part of this peer-to-peer network.|","Bitcoin, an electronic cash, was shared online by a pseudonym with code 10 years ago.|",6
"obvious is what is a cryptocurrency? So this word was kind of invented 10 years ago when, I don't know how many of you know the origin story of where Bitcoin came from, but basically a pseudonym on the internet dropped a paper and some open source code in a forum on an email list and said, hey, I have this idea for this thing called Bitcoin. It's kind of like electronic cash. Here's how I think it could work. And here is some code if you want to run it and become part of this peer-to-peer network.|","Bitcoin, which is like electronic cash, was shared by a pseudonym with code over 10 years ago.|",5
"obvious is what is a cryptocurrency? So this word was kind of invented 10 years ago when, I don't know how many of you know the origin story of where Bitcoin came from, but basically a pseudonym on the internet dropped a paper and some open source code in a forum on an email list and said, hey, I have this idea for this thing called Bitcoin. It's kind of like electronic cash. Here's how I think it could work. And here is some code if you want to run it and become part of this peer-to-peer network.|","Over a decade ago, Bitcoin was introduced as electronic cash by a pseudonym who shared a paper and code.|",4
"obvious is what is a cryptocurrency? So this word was kind of invented 10 years ago when, I don't know how many of you know the origin story of where Bitcoin came from, but basically a pseudonym on the internet dropped a paper and some open source code in a forum on an email list and said, hey, I have this idea for this thing called Bitcoin. It's kind of like electronic cash. Here's how I think it could work. And here is some code if you want to run it and become part of this peer-to-peer network.|","More than a decade ago, a pseudonym introduced Bitcoin as electronic cash, sharing a paper and some code on the internet forum.|",3
"obvious is what is a cryptocurrency? So this word was kind of invented 10 years ago when, I don't know how many of you know the origin story of where Bitcoin came from, but basically a pseudonym on the internet dropped a paper and some open source code in a forum on an email list and said, hey, I have this idea for this thing called Bitcoin. It's kind of like electronic cash. Here's how I think it could work. And here is some code if you want to run it and become part of this peer-to-peer network.|","Bitcoin's introduction as electronic cash happened over a decade ago through a pseudonym, who shared a paper and some open-source code on an internet forum.|",2
"obvious is what is a cryptocurrency? So this word was kind of invented 10 years ago when, I don't know how many of you know the origin story of where Bitcoin came from, but basically a pseudonym on the internet dropped a paper and some open source code in a forum on an email list and said, hey, I have this idea for this thing called Bitcoin. It's kind of like electronic cash. Here's how I think it could work. And here is some code if you want to run it and become part of this peer-to-peer network.|","Over a decade ago, a pseudonym on the internet shared a paper and open-source code in a forum, introducing the idea of Bitcoin as an electronic cash system and how it could work, inviting others to run the code and join the peer-to-peer network.|",1
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The creator is unknown and has vanished online, but their innovation has captured imaginations and generated billions in value, inspiring solutions for various problems beyond payments. Cryptocurrencies and blockchain technology encourage banking for the unbanked, enhance auditability and traceability, eliminate trusted intermediaries, and propose solutions to numerous issues. This class, however, focuses on a different topic.",1
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The anonymous creator has disappeared but has inspired many with a technology generating billions and offering solutions beyond payments. Cryptocurrencies and blockchain technology encourage banking the unbanked, improving traceability, and solving various issues. This class focuses on a different topic.",2
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The originator is unknown and gone from the internet, yet has sparked innovation leading to billions in value. Blockchain and cryptocurrencies urge banking for the unbanked and offer solutions to various problems. However, this class is on a different subject.",3
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The unknown creator has vanished but sparked innovations generating billions. Blockchain and cryptocurrency solutions extend beyond payments, aiding the unbanked and tracing transactions. This class discusses another subject.",4
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The anonymous creator vanished but sparked technology generating billions, inspiring solutions beyond payments, and aiding the unbanked. However, this class has a different focus.",5
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The unknown creator vanished but created a valuable technology. It inspires solutions for payments and banking the unbanked. However, this class covers a different topic.",6
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The unknown creator is gone but made a valuable innovation. This technology inspires solving payment and banking issues. This class, however, is on a different topic.",7
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.","The unknown creator has vanished but made a valuable technology, inspiring solutions beyond payments. This class covers something else.",8
"We don't know who this person is. This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about.",The unknown creator made valuable technology. This class covers a different subject.,9
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","This class is all about technology and infrastructure, not applications. You'll learn to create cryptocurrencies, understand their components, and decide how to use them, but not for digital identity or health care.",1
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","The class focuses on technology and infrastructure, emphasizing creating and understanding cryptocurrencies. You decide the applications, excluding digital identity or health care.",2
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","Focus is on tech and infrastructure, creating and understanding cryptocurrencies. Application choices are up to you but exclude digital identity and healthcare.",3
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","The class focuses on tech and infrastructure, teaching you about cryptocurrencies. Choose your applications, but not for digital identity or healthcare.",4
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","The class covers technology and infrastructure, teaching you to create cryptocurrencies. Choose how to apply them, but not for identity or healthcare.",5
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","The class is about technology and infrastructure, teaching cryptocurrency creation. You choose the application, but not for identity or healthcare.",6
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","The class focuses on tech and infrastructure, teaching you to create cryptocurrencies. Choose applications but not for digital identity or healthcare.",7
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","Learn about tech, infrastructure, and creating cryptocurrencies. You decide the application, excluding digital identity and healthcare.",8
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","This class covers tech and infrastructure, focusing on cryptocurrencies. You pick the application, except for identity or healthcare.",9
"This class is not going to be about applications. This class is going to be about technology and infrastructure. You are going to learn how to create a cryptocurrency, what goes inside a cryptocurrency, what's important, what are the techniques, and what application you choose to apply that to down the line. That's kind of up to you. But we're not going to be doing digital identity or health care records or something like that.","Focus on tech and infrastructure, not applications. Learn to make cryptocurrencies and choose applications, excluding identity or healthcare.",1
"We're going to be talking about the technology. So a big question is how are cryptocurrencies different from regular currencies? And another thing that I want to make really clear is that the terms in this space are still being defined. So you will hear people throw around all sorts of terms, cryptocurrency, blockchain, consensus. And these words are kind of have floating evolving meanings right now.","We will discuss technology and how cryptocurrencies differ from regular currencies. Also, terms in this space are still evolving.",1
"We're going to be talking about the technology. So a big question is how are cryptocurrencies different from regular currencies? And another thing that I want to make really clear is that the terms in this space are still being defined. So you will hear people throw around all sorts of terms, cryptocurrency, blockchain, consensus. And these words are kind of have floating evolving meanings right now.",We will discuss how cryptocurrencies are different from regular money. Terms in this space are still changing.,2
"We're going to be talking about the technology. So a big question is how are cryptocurrencies different from regular currencies? And another thing that I want to make really clear is that the terms in this space are still being defined. So you will hear people throw around all sorts of terms, cryptocurrency, blockchain, consensus. And these words are kind of have floating evolving meanings right now.","We’ll discuss tech and how cryptocurrencies differ from regular money, with terms still evolving.",3
"We're going to be talking about the technology. So a big question is how are cryptocurrencies different from regular currencies? And another thing that I want to make really clear is that the terms in this space are still being defined. So you will hear people throw around all sorts of terms, cryptocurrency, blockchain, consensus. And these words are kind of have floating evolving meanings right now.",We’ll talk about tech and how cryptocurrencies are different from regular money. Terms are still changing.,4
"We're going to be talking about the technology. So a big question is how are cryptocurrencies different from regular currencies? And another thing that I want to make really clear is that the terms in this space are still being defined. So you will hear people throw around all sorts of terms, cryptocurrency, blockchain, consensus. And these words are kind of have floating evolving meanings right now.","We're discussing how cryptocurrencies differ from regular money, and terms are still evolving.",5
"We're going to be talking about the technology. So a big question is how are cryptocurrencies different from regular currencies? And another thing that I want to make really clear is that the terms in this space are still being defined. So you will hear people throw around all sorts of terms, cryptocurrency, blockchain, consensus. And these words are kind of have floating evolving meanings right now.",We discuss how cryptocurrencies are different from regular money and how terms are still evolving.,6
"We're going to be talking about the technology. So a big question is how are cryptocurrencies different from regular currencies? And another thing that I want to make really clear is that the terms in this space are still being defined. So you will hear people throw around all sorts of terms, cryptocurrency, blockchain, consensus. And these words are kind of have floating evolving meanings right now.","We will discuss tech and how cryptocurrencies differ from regular money, with terms evolving.",7
"We're going to be talking about the technology. So a big question is how are cryptocurrencies different from regular currencies? And another thing that I want to make really clear is that the terms in this space are still being defined. So you will hear people throw around all sorts of terms, cryptocurrency, blockchain, consensus. And these words are kind of have floating evolving meanings right now.","We discuss tech and how cryptocurrencies differ, with terms still changing.",8
"We're going to be talking about the technology. So a big question is how are cryptocurrencies different from regular currencies? And another thing that I want to make really clear is that the terms in this space are still being defined. So you will hear people throw around all sorts of terms, cryptocurrency, blockchain, consensus. And these words are kind of have floating evolving meanings right now.",We discuss how cryptocurrencies differ; terms are still changing.,9
"Part of that is because Bitcoin, the first cryptocurrency, didn't come from academia as far as we know. It came from a community of enthusiasts on the internet. And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study. It's totally OK. We're figuring it out as we go along. And academia is really embracing this topic.","Bitcoin was not created in academia but by internet enthusiasts, so it lacks academic rigor. This is fine, and academia is embracing the topic.",9
"Part of that is because Bitcoin, the first cryptocurrency, didn't come from academia as far as we know. It came from a community of enthusiasts on the internet. And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study. It's totally OK. We're figuring it out as we go along. And academia is really embracing this topic.","Bitcoin's origin is not academic but from internet enthusiasts, lacking academic rigor. Yet academia is accepting it.",8
"Part of that is because Bitcoin, the first cryptocurrency, didn't come from academia as far as we know. It came from a community of enthusiasts on the internet. And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study. It's totally OK. We're figuring it out as we go along. And academia is really embracing this topic.","Bitcoin wasn't from academia, but from online enthusiasts, so it lacks scholarly rigor. Academia is still adopting it.",7
"Part of that is because Bitcoin, the first cryptocurrency, didn't come from academia as far as we know. It came from a community of enthusiasts on the internet. And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study. It's totally OK. We're figuring it out as we go along. And academia is really embracing this topic.","Bitcoin originated from web enthusiasts, not academia, thus missing academic rigor. But academia is accepting it.",6
"Part of that is because Bitcoin, the first cryptocurrency, didn't come from academia as far as we know. It came from a community of enthusiasts on the internet. And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study. It's totally OK. We're figuring it out as we go along. And academia is really embracing this topic.","Bitcoin didn't come from academia but online enthusiasts, hence lacks scholarly basis. Academia is embracing it anyway.",5
"Part of that is because Bitcoin, the first cryptocurrency, didn't come from academia as far as we know. It came from a community of enthusiasts on the internet. And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study. It's totally OK. We're figuring it out as we go along. And academia is really embracing this topic.","Bitcoin, not from academia, originated from internet enthusiasts, so it lacks academic rigor. Academia is still embracing it.",4
"Part of that is because Bitcoin, the first cryptocurrency, didn't come from academia as far as we know. It came from a community of enthusiasts on the internet. And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study. It's totally OK. We're figuring it out as we go along. And academia is really embracing this topic.","Bitcoin didn't emerge from academia but from web enthusiasts, hence it lacks scholarly rigor. Nonetheless, academia is adopting it.",3
"Part of that is because Bitcoin, the first cryptocurrency, didn't come from academia as far as we know. It came from a community of enthusiasts on the internet. And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study. It's totally OK. We're figuring it out as we go along. And academia is really embracing this topic.","Bitcoin did not emerge from academia but from online enthusiasts, lacking academic rigor. Academia, however, is starting to accept it.",2
"Part of that is because Bitcoin, the first cryptocurrency, didn't come from academia as far as we know. It came from a community of enthusiasts on the internet. And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study. It's totally OK. We're figuring it out as we go along. And academia is really embracing this topic.","Bitcoin, originating from enthusiasts on the internet rather than academia, lacks scholarly rigor. Nevertheless, academia is beginning to adopt it.",1
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|","For grad students seeking research topics, consider cryptocurrencies; publication rates in respected journals are doubling annually, presenting vast opportunities. Cryptocurrencies are not typical currencies like dollars or euros.|",1
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|","Graduate students searching for research topics should consider cryptocurrencies; the number of published papers is doubling each year, indicating great potential. Cryptocurrencies are unlike traditional currencies.|",2
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|","If you are a graduate student, research cryptocurrency. The number of publications doubles yearly, presenting great opportunities. Cryptocurrencies are unlike traditional currencies.|",3
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|","Grad students should research cryptocurrency. Publications are doubling each year, indicating massive potential. Cryptocurrencies differ from traditional currencies.|",4
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|","Graduate students should investigate cryptocurrencies. The number of papers doubles yearly, offering vast opportunity. Cryptocurrencies are unlike dollars or euros.|",5
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|","Grad students should study cryptocurrencies, as the number of papers doubles yearly, showing great potential. Cryptocurrencies differ from traditional currencies like dollars or euros.|",6
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|","Grad students should explore cryptocurrencies. The number of papers on this subject is doubling yearly, indicating tremendous opportunity. Cryptocurrencies differ from normal currencies like dollars or euros.|",7
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|","Grad students interested in research should consider cryptocurrencies, as papers on this topic double yearly. Cryptocurrencies are different from dollars or euros.|",8
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|",Grad students should look into cryptocurrencies; paper numbers on this topic are doubling yearly. Cryptocurrencies are not like dollars or euros.|,9
"So if any of you are graduate students who are looking for an area in which to do research, I think basically the number of papers published on cryptocurrencies and blockchain technology in respected academic venues is doubling every year. So there's huge opportunity here. So cryptocurrencies are not regular currencies. They're not a dollar or a pound or a euro, what we normally think of as currency. There's something different.|","Grad students, research cryptocurrencies; annual paper numbers are doubling. Cryptocurrencies are unlike dollars or euros.|",1
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin emerged from nothing. What does creating crypto mean? I'll show a picture to show our skill in recognizing emotions. In the image, we don't know the people but can feel the mood. It's positive, and they seem connected.|",9
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin was created seemingly from nowhere. What is it to create a cryptocurrency? I'll show a picture to showcase our emotion recognition skills. This image allows us to infer the atmosphere as positive, despite not knowing the individuals.|",8
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin seemed to be created out of nowhere. What does it mean to create cryptocurrency? I will show you a picture illustrating our incredible ability to recognize emotions. When looking at the picture, we see people we don't know, but we can sense a positive mood and a connection between them.|",7
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin was apparently created from nowhere. Creation of cryptocurrency is an interesting question. I'll show a picture to highlight our ability to recognize emotions. The image shows people whose details we don't know, but we can perceive a positive atmosphere and a sense of connection among them.|",6
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin appeared to come from nothing. The idea of creating cryptocurrency raises questions. I will display a picture to illustrate how adept we are at recognizing emotions. Although we know nothing about the people in the image, we can sense their positive mood and engagement with each other.|",5
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin came out of nowhere. So what does creating cryptocurrency mean? I'll show a picture that highlights our emotional recognition skills. When we see the image, we don't know the people, but we perceive a positive atmosphere and sense their connection.|",4
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin emerged from nowhere. What does creating a cryptocurrency entail? I'm presenting a picture to emphasize our remarkable ability to discern emotions. Viewing the image, we glean a positive atmosphere and a sense of connection from people we don't know.|",3
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin seemed to be made from nothing. The concept of creating cryptocurrency is intriguing. I will show you a picture illuminating our extraordinary emotional recognition. Observing the picture, despite knowing nothing about the individuals, we perceive a positive atmosphere and their interaction.|",2
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin appeared to come from nothing. The act of creating crypto poses interesting questions. I will show you an image that displays our incredible ability to recognize emotions. Even without knowing the people, the image allows us to sense the positive vibe and connection among them.|",1
"Bitcoin was sort of created out of nowhere. And what does it mean to create a crypto? And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions. So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right? We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.|","Bitcoin appeared from nowhere. What is the essence of creating cryptocurrency? I will present an image to showcase our emotion recognition skills. We don't know these individuals, but the positive atmosphere and their connection is noticeable from the image.|",1
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.",We capture emotional information with an image. Understanding emotions is vital for our social interactions. We guess how others feel to adapt communication.,9
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","Emotional data is captured by one image, helping us recognize others' feelings. It's crucial for social interactions and adapting our communication.",8
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.",We capture emotions with one image. This ability is vital for social interactions and helps us adapt communication to how others feel.,7
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","One image captures emotional information. Recognizing emotions aids social interactions, adapting how we communicate.",6
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","Emotional info from one image helps us recognize feelings, crucial for social interaction and how we communicate.",5
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","One image captures emotional details, aiding in recognizing emotions for social interaction and adjusting communication.",4
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.","Emotional information is captured from an image. This helps us recognize emotions, very useful in social interactions to adapt communication.",3
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.",Recognizing emotions from one image provides emotional information critical for social interactions and communication adjustments.,2
"All of that is emotional information that we can capture just with one image. We have this remarkable capacity for recognizing emotions. Why is this capacity useful for us? It's very important in our social interactions. When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.",Emotional recognition from an image gives information crucial for social interaction and communication adjustment.,1
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Identifying people's needs and predicting their reactions is crucial. Emotions significantly impact our cognitive processes, such as attention, memory, and learning. Given the importance of emotions, envisioning future AI becomes pertinent. How many have seen any of these movies?",1
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","It's crucial to detect people's needs and predict their reactions. Emotions influence cognition, affecting attention, memory, and learning. How many have seen these movies?",2
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Detecting needs and predicting reactions are essential. Emotions affect attention, memory, and learning. Have you seen these movies?",3
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","It is important to detect needs and predict reactions. Emotions affect attention, memory, and learning. How many have seen these movies?",4
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Detecting needs and predicting reactions is vital. Emotions affect thinking processes, attention, memory, and learning. Seen these movies?",5
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","It's vital to understand needs and predict reactions. Emotions influence thinking, attention, memory, and learning. Seen these movies?",6
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","It’s key to detect needs and predict reactions. Emotions impact thinking, attention, memory, and learning. Have seen these movies?",7
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Know needs, predict reactions. Emotions affect thinking, attention, learning. Seen the movies?",8
"It's very important to detect people's needs as well, and also to predict people's reactions. And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes. So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here?","Know needs, predict reactions. Emotions affect thinking, memory, learning. Seen the movies?",9
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|","Most have seen at least one future machine movie with emotional intelligence. Emotions are complex, hard to understand, and it's difficult to measure how others feel.|",1
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",You know future machines in movies have emotional intelligence. Emotions are complex and it's tough to understand how others feel.|,2
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|","Machines in movies have emotional intelligence, but emotions are complex and hard to understand.|",3
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Future machines in movies have emotional intelligence. Emotions are tough to understand.|,4
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Machines in future movies have emotional intelligence. Emotions are complex.|,5
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Machines in future movies are emotionally intelligent. Understanding emotions is hard.|,6
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Movies feature future machines with emotional intelligence. Emotions are tricky.|,7
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Future movies show machines with emotions. Emotions are complex.|,8
"So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right? Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel.|",Future movies show machines with emotional intelligence.|,9
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Understanding emotions is complex for machines because emotions cause many body changes. When nervous, our heart and respiration rates go up, we sweat, and our facial expressions, gaze, pupils, blood pressure, postures, and gestures all change.",1
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines find it hard to understand emotions because of the many changes in the body when we're nervous, such as heart and respiration rate increases, sweating, and changes in facial expressions, gaze, pupils, blood pressure, and gestures.",2
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines can't easily recognize emotions because body signs change a lot when we're nervous, including heart and breath rate, sweating, facial expressions, gaze, pupils, blood pressure, and gestures.",3
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines struggle with understanding emotions because body signs change with feelings, like heart and breath rate, sweating, gaze, facial expressions, pupils, blood pressure, and gestures.",4
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines find emotions hard to understand because body signs like heart rate, breath rate, sweating, facial expressions, gaze, pupils, blood pressure, and gestures change.",5
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines struggle because our emotions cause many body changes, like heart rate, breath rate, sweat, facial expressions, gaze, pupils, blood pressure, and gestures.",6
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines find emotions hard to understand because body changes like heart rate, breath rate, sweating, expressions, gaze, pupils, blood pressure, and gestures differ.",7
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines struggle to grasp emotions because many body changes occur, like heart rate, breath rate, sweat, expressions, gaze, pupils, blood pressure, and gestures.",8
"So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures. We use different gestures depending on how we feel.","Machines struggle with emotions because body signs like heart rate, breath rate, sweat, expressions, gaze, pupils, blood pressure, and gestures change.",9
"Our voice can change as well, the way we write, the way we type in our phones, for instance.",The way we speak and write can change.,9
So there are a lot of signals that change with our emotions.,Many signals change with our emotions.,9
So what we can do is all of these signals can be captured with different types of sensors.,Many sensors can capture these signals.,9
"And then we capture these signals, and if we have data, label data with emotions,",We capture signals and label data with emotions.,8
What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information.,We can find patterns in signals and develop machine learning to recognize emotions.,6
The same way we process other type of information.,Just like we process other information.,8
"Our voice can change as well, the way we write, the way we type in our phones, for instance.",Our voice and writing change with emotions.,7
So there are a lot of signals that change with our emotions.,Emotions change many signals in us.,7
So what we can do is all of these signals can be captured with different types of sensors.,Different sensors can capture these signals.,8
"And then we capture these signals, and if we have data, label data with emotions,","We capture signals, label them with emotions.",7
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?","Initially, I will discuss how we capture emotional data, starting with my expertise in visual modality and cameras. What has been done to recognize emotions through visual data?",1
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?","I will start with vision modality to capture emotional information. With cameras, how has emotion recognition been achieved?",2
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",Let’s focus on how to capture emotional data using visual modality and cameras. What progress has been made in emotion recognition?,3
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",We will look at capturing emotions with vision modality. How have cameras been used for emotion recognition so far?,4
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?","Let's examine how to capture emotions using vision modality, especially with cameras. How has emotion recognition been approached?",5
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",Let’s talk about capturing emotional information using visual modality and cameras. What has been done so far for emotion recognition?,6
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",I will discuss how we capture emotional data using visual modality and cameras. What's been done for recognizing emotions?,7
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",I'll discuss capturing emotional information with visual modality. How do cameras recognize emotions?,8
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",Let's focus on how we capture emotions with cameras. What has been done in this area?,9
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea?",How do we capture emotions with cameras? What has been done in this field?,1
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",The primary method in computer vision to recognize emotions is facial expression.,9
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",The main research theme in computer vision for emotion recognition is facial expressions.,8
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",The most frequent technique to recognize emotions in computer vision is facial expressions.,7
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Facial expression analysis is widely used in computer vision research for emotion recognition.,6
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Facial expressions are predominant in computer vision research for recognizing emotions.,5
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Recognizing emotions through facial expressions is a key topic in computer vision research.,4
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Emotion recognition via facial expressions is a significant area of computer vision research.,3
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Computer vision research significantly focuses on recognizing emotions through facial expressions.,2
"What's the most popular research from a computer vision perspective to recognize emotions? So facial expression is actually the most common approach to recognize emotions. So when I was doing my PhD, I finished like 10 years ago now. And this was a completely unsolved problem. So I was working a little bit in this type of software, trying to recognize key points in the faces, working with images acquired under controlled environments, and nothing was working by then.",Recognizing emotions through facial expressions has been a major unsolved problem in computer vision.,1
"So now after 10 years, we have these softwares that work very well in recognizing some of the key points on your face, tracking these key points, and doing some matching between the emotions, so the expressions that are observed and the possible emotions that they are expressing.","After a decade, software effectively identifies facial key points and matches them to possible emotions.",1
"This is an example of a commercial software from a company called Affectiva, where you see that the software detects your key points, analyzes the configuration, and makes some kind of correspondence between this expression and the possible emotion that you are expressing with the facial expression.","Affectiva's commercial software detects key facial points, analyzes them, and matches expressions to emotions.",2
"This software works very well, so it's very well at detecting the patterns, it's very while detecting the key points, it's complicated to associate the correct emotion to an expression, a phase expression, but it works pretty well in some applications.",This software detects patterns and key points well but struggles to accurately match expressions to emotions.,3
"It's being used for test users, for instance, but the problem of this software is that it does not work in the wild.",It is used for test users but fails to work in uncontrolled environments.,4
So we would like to have machines that can recognize emotions in any condition.,We want machines that can detect emotions in all conditions.,5
"So now after 10 years, we have these softwares that work very well in recognizing some of the key points on your face, tracking these key points, and doing some matching between the emotions, so the expressions that are observed and the possible emotions that they are expressing.",Advanced software now accurately tracks facial points and matches them to emotions.,6
"This is an example of a commercial software from a company called Affectiva, where you see that the software detects your key points, analyzes the configuration, and makes some kind of correspondence between this expression and the possible emotion that you are expressing with the facial expression.","Affectiva's software finds facial points, analyzes them, and matches them with possible emotions.",7
"This software works very well, so it's very well at detecting the patterns, it's very while detecting the key points, it's complicated to associate the correct emotion to an expression, a phase expression, but it works pretty well in some applications.",The software detects patterns well but struggles to match expressions with emotions.,8
"It's being used for test users, for instance, but the problem of this software is that it does not work in the wild.","Used in tests, the software fails in uncontrolled settings.",9
So we would like to have machines that can recognize emotions in any condition.,We want machines to detect emotions everywhere.,1
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","Upon running commercial software on this image, it successfully detects the woman's face, key points, smile, and attention, saying she feels happy. However, it fails to work on him.",1
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","Running the software on the image reveals the woman's face, key points, and smile accurately, indicating happiness, but fails to function for him.",2
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","Running the software detects the woman’s face, key points, smile, and attention accurately, indicating happiness. It does not function for him.",3
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","The software detects the woman's face, key points, smile, and attention, indicating happiness, but it fails for him.",4
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","The software finds the woman’s face, key points, smile, and attention. It indicates happiness but fails for him.",5
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","The software detects the face, key points, smile, and attention of the woman. It shows happiness but fails with him.",6
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","This software recognizes the woman's face, key points, smile, and attention, indicating happiness, but it doesn't work for him.",7
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","The software spots the woman's face, key points, smile, and attention, showing happiness, but it doesn't work for him.",8
"So, if we go back to this image that I showed you before, what happens when we run this type of software here? So if we run this type of commercial software, we can detect very well the face of this woman, we can detect the key points, and the software is answering in this case that this woman is feeling happiness because it detects a smile with a strong confidence, it detects attention. I don't know exactly how this detection of attention works here, but actually it's pretty accurate. But what happens with him? So what happens with him is that the system is not working.","The software sees the woman’s face, key points, smile, and attention, indicating happiness, but fails with him.",9
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|","The problem is key facial points are obscured by glasses and profile view. In open environments, facial recognition software struggles with nonfrontal faces and occlusions.|",9
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|","The issue is the key facial points are obscured, mainly due to glasses and a side view. Recognition software fails with nonfrontal faces and occlusions in open settings.|",8
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|","Key facial points are hidden due to glasses and a profile view. In open environments, facial recognition software struggles with nonfrontal faces and occlusions, leading to problems.|",7
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|","Key facial features are obscured by glasses and a side view. In open settings, facial recognition software fails with nonfrontal faces and occlusions, causing issues.|",6
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|",Facial key points are hidden by glasses and a side view. Recognition software often fails in open environments due to nonfrontal faces and occlusions.|,5
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|","The glasses and side view hide key facial points. In open environments, facial recognition software struggles with nonfrontal faces and occlusions.|",4
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|",Glasses and a profile view hide key face points. Facial recognition software often fails in open settings due to nonfrontal faces and occlusions.|,3
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|",Glasses and a side view obscure key face points. Facial recognition software often fails in nonfrontal and occlusion cases in open settings.|,2
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|",Glasses and side view obscure face points. Facial recognition software often fails with nonfrontal faces and occlusions in open environments.|,1
"So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like. More problems.|",Glasses and side view hide key face points. Recognition software fails with nonfrontal faces and occlusions in open areas.|,1
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.","We have another face example. The software detects surprise with an open mouth, a typical expression.",1
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",The software detects a face showing surprise with an open mouth; a common expression.,2
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Another face example shows surprise detected by the software.,3
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.","The software sees a face that shows surprise, mouth open.",4
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.","Software detects a face showing surprise, mouth open.",5
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Face showing surprise is detected by software.,6
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Software detects surprise on face.,7
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Software sees a surprised face.,8
"So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.",Software sees surprise.,9
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","Context shows the facial expression is not surprising and is related to the action being performed, not emotion. Some expressions aren't emotional but functional, like those while talking.",9
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","Context reveals the expression isn't surprising; it's tied to the action, not emotion. Some expressions aren't about feelings, but actions like talking.",8
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","In context, the expression isn't surprising and is related to actions, not emotions. Some expressions are about actions, not feelings, such as during talking.",7
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","In the context, the facial expression isn't surprising and relates to the action, not emotion. Some facial expressions are about actions like talking, not emotions.",6
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","In context, the expression isn't surprising and relates to actions, not emotions. Some expressions are tied to actions like talking, not emotions.",5
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","We see, in context, that the expression isn't surprising and is related to actions, not emotions. Some expressions are tied to actions like talking, not emotions.",4
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","The context shows the surprising expression is about actions, not emotions. Some facial expressions link to actions like talking, not emotions.",3
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","The context shows expression isn't surprising, linked to actions, not emotions. Some facial expressions concern actions such as talking, not feelings.",2
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","Context shows the expression isn't surprising, tied to actions, not feelings. Some facial expressions are about actions like talking, not emotions.",1
"But when we look at the context, we realize that it's not surprise, right? So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing. So some of our facial expressions have nothing to do with our emotions but with other things. For instance, when you talk, you change a lot your facial expression. It has nothing to do with your emotion.","In context, expression isn't surprising. Tied to action, not emotion. Some expressions relate to actions like talking, not emotions.",1
And another difficulty is giving the correct emotional meaning to an isolated facial expression.,Assigning the right emotion to a facial expression is tough.,9
"So I'm going to show you some examples of experiments that were performed by psychologists that were studying what's the level of agreement in giving an emotional label to a specific facial expression, like here.",Here are experiments by psychologists on agreement in labeling emotions in facial expressions.,4
"So here we see clearly a facial expression, but if I ask you, what's this facial expression communicating? Well, you might think maybe anger, maybe contempt, this gas fear.|","What emotion does this facial expression show? Anger, contempt, or fear?",8
"So usually people agree that this is a negative, valence emotion, but it's not clear what category.|","People generally agree it's a negative emotion, but the exact category is unclear.",6
And another difficulty is giving the correct emotional meaning to an isolated facial expression.|,Another challenge is identifying the correct emotion in a single facial expression.,5
"So I'm going to show you some examples of experiments that were performed by psychologists that were studying what's the level of agreement in giving an emotional label to a specific facial expression, like here.|",I will show experiments by psychologists on agreement in labeling a facial expression.,7
"So here we see clearly a facial expression, but if I ask you, what's this facial expression communicating? Well, you might think maybe anger, maybe contempt, this gas fear.|","Here is a facial expression; does it show anger, contempt, or fear?",8
"So usually people agree that this is a negative, valence emotion, but it's not clear what category.|","People typically agree it shows a negative emotion, though the category is fuzzy.",6
And another difficulty is giving the correct emotional meaning to an isolated facial expression.|,It is hard to give the right emotional meaning to a single facial expression.,5
"So I'm going to show you some examples of experiments that were performed by psychologists that were studying what's the level of agreement in giving an emotional label to a specific facial expression, like here.|",Here are psychologist experiments on agreement in emotional labeling of expressions.,4
"The thing is that if I give you some context suddenly, we probably will agree that this is disgust and this is what happens.","With sudden context, we likely agree it is disgust.",5
People agree here that the face is disgust.,People agree the face shows disgust.,7
"But if you give you a different context, then people strongly agree that this is anger.","In a different context, people agree it is anger.",6
So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts.,They have many examples and do experiments using the same facial expressions in different contexts.,4
And they realize that the context strongly influences the way we perceive emotions.,They find that context strongly affects how we perceive emotions.,6
"So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face.","This project, started in Barcelona with MIT, aims to make machines understand emotions not just from faces but also from context.",9
"We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person.",Understanding the scene context is critical for recognizing a person's emotions.,8
And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.,Analyzing context provides deeper insights about emotions.,8
"So maybe with the expression, you can say something about basic emotions, but there are some secondary emotions or social emotions that are very interesting that if you don't see the context, you cannot say anything about them.","Facial expressions reveal basic emotions, but context is needed for secondary or social emotions.",6
"Like here, once you see the context, you might say that this person is feeling confident.","Seeing context can reveal emotions, like confidence.",9
"And the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face.","To improve emotion recognition, machines need the context, not just facial data.",7
"In particularly we are working in the scene context, in the situation of the person.",We're focusing on the person's situational context.,8
The interesting thing of working in this type of context is that suddenly you can say much more about the emotion.,Context allows for a richer understanding of emotion.,8
"For developing machines that accurately recognize emotions, we can just rely on the face.",Reliable emotion recognition requires more than just facial data.,9
"There are some secondary emotions or social emotions that are very interesting that if you don't see the context, you cannot say anything about them.","Without context, secondary and social emotions cannot be understood.",8
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Defining confidence involves feeling sure, convinced of favorable outcomes, encouraged, or proud. This forms the basis of our emotion recognition project. We aim to use images for emotion recognition, considering the context, not just facial features. This is a computer vision project, and deep learning is the most effective approach currently. So we plan to use deep learning to tackle this issue.",1
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence is the feeling of certainty or pride in favorable outcomes. This guides our emotion recognition project, focusing on images to detect emotions, considering both face and context. As a computer vision project, deep learning is our chosen approach to model this problem.",2
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence means feeling sure, proud, or encouraged about favorable outcomes. Our emotion recognition project focuses on using images to detect emotions, considering faces and context. As a computer vision project, we use deep learning to solve this problem.",3
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence, a sense of assurance and pride in positive outcomes, is the basis for our emotion recognition project. We use images to detect emotions, considering faces and context. As a computer vision project, we utilize deep learning to solve this issue.",4
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence is assurance and pride in positive outcomes, guiding our emotion recognition project. We analyze images to detect emotions using both face and context. This computer vision project uses deep learning to address the task.",5
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence is the feeling of assurance and pride. Our project aims to detect emotions in images, considering face and context. This computer vision task uses deep learning.",6
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence is being sure and proud. The goal is to detect emotions in images, using faces and context. This project uses deep learning in computer vision.",7
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.","Confidence means being sure and proud. The project detects emotions in images, considering face and context, using deep learning.",8
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud. So that's the idea of the emotion recognition in context project. So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project. We know that in computer vision nowadays what is working best is deep learning models. So our idea was, okay, let's try to model this problem using deep learning.",Confidence is certainty and pride. We detect emotions in images using deep learning.,9
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","Our initial challenge was the absence of training data for emotion recognition from images that included people in context. We gathered many images, some manually from Google and others from labeled public data sets. These images show people in various situations, and we created annotation interfaces for them.",1
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","Due to the lack of contextual training data, we collected images from Google and public data sets, showing people in various scenarios, and created annotation interfaces.",2
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","Lacking training data for emotion recognition in context, we gathered images manually from Google and public data sets, then created annotation interfaces for varied scenarios.",3
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","We faced a challenge with no training data, collected images from Google and public sets, and created annotation tools showing people in various contexts.",4
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","We lacked training data, so we collected images from Google and public data sets, then made annotation tools for varied contexts.",5
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","We didn't have training data, collected images from Google and public sets, and made annotation tools for varied scenarios.",6
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","Lacking data, we collected images from Google and public sets and created tools for varied contexts.",7
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","Without data, we gathered images from Google and public sets and made annotation tools.",8
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.","We lacked data, collected images, and made annotation tools.",9
"So first challenge that we faced, we didn't have any training data, of course, because as we said before, usually all the research on emotion recognition from images was focused on the face, so we didn't have any data set where we could see people in their context. So we were collecting a lot of images. Some of them were manually downloaded from search engines like Google, and other images came from public data sets that were already labeled with the bounding box of the person. And the images we collected are images like the ones that you see here, so people doing different things in very different situations. And what we did is we created annotation interfaces like this one that I'm showing you here.",We collected images and made tools.,1
So where we asked annotators to label what emotion category they thought this person was expressing in this specific situation.,Annotators labeled the emotion category expressed by this person in this situation.,1
We had two different interfaces.,We had two interfaces.,9
This is the one of emotion categories.,This is one of the emotion categories.,8
And we have another one for continuous dimensions.,We also have one for continuous dimensions.,7
So there are different ways of representing emotions in a machine.,There are different ways to represent emotions in a machine.,6
So where we asked annotators to label what emotion category they thought this person was expressing in this specific situation.,We asked annotators to label the emotion category in this specific situation.,5
We had two different interfaces.,Two different interfaces were available.,4
This is the one of emotion categories.,This pertains to emotion categories.,3
And we have another one for continuous dimensions.,Another interface is for continuous dimensions.,2
So there are different ways of representing emotions in a machine.,Emotions can be represented in a machine in different ways.,1
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common; emotional dimensions less so. Valence measures if feelings are positive or negative. Arousal indicates calmness or readiness to act, while dominance shows control or lack thereof.",9
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are well-known, while emotional dimensions are less common. Valence gauges positive or negative feelings. Arousal measures calmness or agitation. Dominance assesses control or feeling dominated.",8
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, emotional dimensions less so. Valence identifies positive or negative emotions. Arousal measures calmness or agitation, and dominance shows control or dominance.",7
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, emotional dimensions less known. Valence measures positive or negative emotions. Arousal assesses calmness or agitation. Dominance indicates control or domination.",6
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, emotional dimensions less so. Valence gauges if emotions are positive or negative, arousal measures calmness or agitation, and dominance shows control or domination.",5
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, emotional dimensions less familiar. Valence measures positive or negative feelings, arousal indicates calm or agitated states, and dominance shows if one feels controlled or in control.",4
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are frequent, emotional dimensions less known. Valence measures positive or negative, arousal measures calm or ready states, and dominance indicates controlled or in control feelings.",3
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are common, but emotional dimensions are less so. Valence gauges positive or negative feelings. Arousal measures calmness or agitation. Dominance assesses if one feels controlled or in control of the situation.",2
"Categories is one of the most common and emotional dimensions is the other one. Maybe it's less popular. But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative. A rousal is measuring whether someone is in calm or very ready to act, very agitated. And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.","Categories are frequent, but emotional dimensions are not as popular. Valence measures whether feelings are positive or negative. Arousal measures calmness or agitation. Dominance evaluates if someone feels in control or dominated by the situation.",1
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","Demographics, like gender and estimated age, were collected from pictures using Amazon Mechanical Turk. The resulting emoric data set has 23,000 images and 34,000 people annotated, with some pictures containing multiple people.",1
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","Demographics of people in pictures, such as gender and age, were collected using Amazon Mechanical Turk, creating the emoric data set with 23,000 images and 34,000 people.",2
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","We collected demographics of people in the picture using Amazon Mechanical Turk, creating a data set of 23,000 images and 34,000 people.",3
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","Using Amazon Mechanical Turk, we collected demographics like gender and age from pictures, creating a data set of 23,000 images and 34,000 people.",4
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","We collected demographics like gender and age of people in pictures using Amazon Mechanical Turk, creating a large data set.",5
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","Using Amazon Mechanical Turk, we collected demographics such as gender and age from pictures, creating a large data set.",6
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","We used Amazon Mechanical Turk to collect demographics such as gender and age from pictures, creating a big data set.",7
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.",We used Amazon Mechanical Turk to gather demographics like gender and age from pictures into a big data set.,8
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age. And we use cloud sourcing for collecting all of these annotations. In particular, we use the platform Amazon Mechanical Turk. And after this process, we came up with what we call the emoric data set, which is a collection of these images, 23,000 annotated images, 34,000 annotated people. Because for some images, we have multiple people annotated.","Using Amazon Mechanical Turk, we gathered demographics like gender and age from photos to make a big data set.",9
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",The deep learning model developed by us is simple; it takes an image and knows the target person's location to recognize their emotion.,1
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.","We developed a baseline deep learning model. It is simple, with an image input and target person's location, to recognize emotions.",2
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",Our simple baseline deep learning model takes an image and identifies the target person to recognize their emotion.,3
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",The simple baseline deep learning model we developed uses images and target locations to recognize emotions.,4
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",We created a simple deep learning model to recognize emotions from an image of a target person.,5
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",We developed a simple model to recognize the target person's emotion from an image.,6
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",Our model recognizes emotions from the target person's image.,7
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",The simple model finds emotions in images.,8
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",The model detects emotions.,9
"I'm going to show you a little bit about the deep learning model that we developed as a baseline to model this problem. So what we did, it's a very simple model. This is the representation of the architecture. So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of. And then we have one module that is extracting person features.",It spots emotions.,1
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We extract features of the person's bounding box using a fully convolutional network. Another module extracts context features from the whole image using another fully convolutional network. We merge these features with one fully connected layer to recognize balance, land dominance, and emotions.",1
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We use a fully convolutional method to get features from the person's bounding box. Another module gets context features from the whole image. We merge these features using one fully connected layer and separate the recognition of balance, land dominance, and emotions.",2
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We get features of the person with a fully convolutional network. Context features from the whole image are extracted by another module. These features are merged with one fully connected layer for recognizing balance, land dominance, and emotions.",3
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We extract features of the person using a fully convolutional network. Context features are gathered from the whole image using another module. We merge these with a fully connected layer to recognize balance, land dominance, and emotions.",4
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We use a fully convolutional network to extract features of the person. Another module extracts context features from the whole image. We merge these features with one layer and identify balance, dominance, and emotions.",5
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We use a convolutional network to get features from the person's bounding box. Context features from the whole image are extracted by another module. These features are merged with one layer to recognize balance, dominance, and emotions.",6
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We use a network to extract features from the person's bounding box. Another module extracts features from the whole image. We merge them with one layer to recognize balance, dominance, and emotions.",7
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We get features from the person's box using a network. Another module gets features from the whole image. We merge them with one layer to recognize balance, dominance, and emotions.",8
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We use a network to get features from the person's box. Another module gets features from the image. We merge them to recognize balance, dominance, and emotions.",9
"So it's fully convolutional and we extract features of the bounding box containing the person. And then we have another module which is the context features that takes as an input the whole image and extract also enough using a fully convolutional network features about the context. And then we merge these features. We have one fully connected layer. And we separate the recognition of balance, and also land dominance, and the emotion categories.","We get features from the person's box with a network. Another module gets features from the image. We merge them to recognize balance, dominance, and emotions.",1
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use a regression loss function as it modeled our data best. We obtained these results and these images. This image recognizes anticipation, excitement, engagement, and confidence. Another image shows recognition, pleasure, happiness, and affection.|",9
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression for our loss function based on our experiments which showed it models data best. These are the results and images we get, recognizing anticipation, excitement, engagement, and confidence in one case, and recognition, pleasure, happiness, and affection in another.|",8
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression as our loss function based on experiments that showed it models data best. These results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",7
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We selected a regression loss function because experiments showed it models data best. The results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",6
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression based on experiments showing it models data best. Results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",5
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We chose regression loss function as experiments showed it models data best. Results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",4
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression after experiments showed it models data best. Results show images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",3
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression because experiments showed it models data best. Results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",2
"And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.|","We use regression since experiments showed it models data best. Results include images recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.|",1
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation.|",The system recognized happiness without seeing the face by extracting context and situational information.|,8
"Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output.|","For one person, emotions like pleasure, affection, and happiness were recognized, but for another, it was chaotic. This shows that the system uses both context and personal information.|",7
"So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context.|","The system's first attempt to recognize emotions using context and person, not just face, isn't working well.|",6
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation.|","The system recognized happiness even without seeing a face, by extracting context and situation.|",8
"Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output.|","Emotions like pleasure, affection, and happiness were recognized for one person but were chaotic for another, showing context and personal info are used.|",5
"So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context.|","The system's first attempt to recognize emotions using situational context and the person, not just the face, is not very successful.|",4
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation.|","The system recognized happiness without using facial information, relying on context and situation instead.|",7
"Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output.|","For one person, emotions of pleasure, affection, and happiness were recognized, but it was chaotic for another, showing both context and personal info are used.|",4
"So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context.|","The system’s initial attempt to recognize emotions using both situational context and personal info, not just the face, isn't effective.|",3
"So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context.|","The system’s initial try to recognize emotions using both situational context and the person, rather than just the face, wasn't effective.|",2
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","The Red House restaurant in Cambridge, Massachusetts, has reviews online that help patrons understand its offerings.|",9
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","In Cambridge, Massachusetts, the Red House restaurant has various reviews you can find online to learn about it.|",8
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","The Red House in Cambridge, MA has online reviews to help new visitors learn about it.|",7
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","Reviews of the Red House, located in Cambridge, Massachusetts, are available online for those who want to learn about it.|",6
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","The Red House restaurant in Cambridge, Massachusetts, has online reviews that offer insights for first-time visitors.|",5
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","You can find reviews of the Red House restaurant in Cambridge, Massachusetts, online to understand how it operates.|",4
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","To learn about the Red House restaurant in Cambridge, MA, you can search online for reviews and find out useful information.|",3
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","When visiting the Red House restaurant in Cambridge, Massachusetts, for the first time, you can look up reviews online to see how it operates.|",2
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","If you visit the Red House restaurant in Cambridge, MA, for the first time and wish to understand its operation, you can find reviews online.|",1
"We are progressing this project in different directions. So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review.|","If you are visiting the Red House restaurant in Cambridge, Massachusetts for the first time and you want to know how the restaurant operates, you may search for online reviews for guidance.|",1
"So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.","It describes a delightful menu, great cocktails, and a relaxed atmosphere with locals and professors.",9
"Okay, so we read this type of reviews and from these reviews, we decide whether we want to go to the restaurant or not.",We read such reviews to decide on visiting the restaurant.,8
Somehow we capture the idea of whether this restaurant is good or not.,We determine if the restaurant is good or not from the review.,7
"But it is not saying, this is a good restaurant, go there or this is not a good restaurant, don't go there.",It does not explicitly say to go or not go to the restaurant.,6
Somehow we capture the idea of whether this restaurant is good or not.,We figure out if the restaurant is good or bad.,5
"So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.",It describes a pleasure with a good menu and atmosphere.,4
"Okay, so we read this type of reviews and from these reviews, we decide whether we want to go to the restaurant or not.",We read reviews to decide if we should visit.,3
"But it is not saying, this is a good restaurant, go there or this is not a good restaurant, don't go there.",It doesn't say to visit the restaurant or not.,2
"We read this type of reviews and from these reviews, we decide whether we want to go to the restaurant or not.",Reviews help us decide to go or not.,1
"It describes a delightful menu, great cocktails, and a relaxed atmosphere with locals and professors.","Reviews describe menu, cocktails, and atmosphere.",1
"So from this type of information, can you tell me if the person that wrote this text was feeling something positive or something negative about the restaurant?",Can you determine if the writer felt positive or negative about the restaurant from this information?,1
Is it positive?,Is it positive?,9
It's very clear.,It's very clear.,8
"For us, it's very easy to do.",It's quite simple for us.,7
So one thing that we can think is maybe we can develop algorithms that do the same.,Perhaps we can create algorithms to do this.,6
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","Researchers study sentiment analysis from text, a field to determine sentiment. One state-of-the-art model is deepmoji, developed at MIT Media Lab, but not in my group.",9
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","Capturing sentiment from text is a focus of much research, known as sentiment analysis. Deep moji, developed at MIT Media Lab, is a leading model but not from my group.",8
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","Sentiment from text is widely researched through sentiment analysis. Deep moji, a top model, is from MIT Media Lab but not my group.",7
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","The study of sentiment analysis from text is extensive. Deep moji is a leading model from MIT Media Lab, not from my group.",6
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","There is much research on capturing sentiment from text. This study is called sentiment analysis. Deep moji, a leading model, was made at MIT Media Lab, not my group.",5
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","Considerable research aims to capture text sentiment, termed sentiment analysis. Deep moji, an advanced model, was made at MIT Media Lab, not by my group.",4
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","Large amounts of research focus on capturing sentiment in text, known as sentiment analysis. Deep moji, a top model, was developed at MIT Media Lab, not in my group.",3
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","A great deal of research goes into capturing sentiment from text. This field is called sentiment analysis. An advanced model from MIT Media Lab is deep moji, but not from my group.",2
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","Extensive research aims to capture sentiment from text, a field known as sentiment analysis. Deep moji is a leading model from MIT Media Lab, but not from my group.",1
"So actually, there's a lot of research in trying to capture sentiment from text. This problem is called sentiment analysis in text. And this is one of the state of the art models. It's called deep moji. It was developed in MIT media lab, not in effective computing group, which is the group I'm working on.","There is a great deal of research aimed at capturing sentiment from texts, known as sentiment analysis. One leading model is deep moji, which was developed at MIT Media Lab, not my group.",1
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","It was made using social machines. Simple method: large data and deep learning. Analyzed 1,200 million tweets with emojis, focusing on 64 common ones.|",1
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","Social machines created it. The concept is simple: large data and deep learning were used. They examined 1,200 million emoji tweets, selecting 64 common ones.|",2
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","Created with social machines. Simple concept involving large data and deep learning. They analyzed 1,200 million emoji tweets and picked 64 common ones.|",3
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","Developed on social machines. Method is simple: large-scale data and deep learning. They took 1,200 million tweets with emojis, focusing on 64 common emojis.|",4
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","Developed using social machines. It's simple: large data and deep learning. They collected 1,200 million tweets with the 64 most common emojis.|",5
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","Created with social machines, the method is simple. Using large data and deep learning, they analyzed 1,200 million tweets with 64 common emojis.|",6
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","Created using social machines, the method is simple. With large data and deep learning, they studied 1,200 million tweets with 64 common emojis.|",7
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","Made with social machines, the method is simple. Using large data and deep learning, they reviewed 1,200 million tweets with 64 common emojis.|",8
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","Social machines made it. The method is simple. They used big data and deep learning and analyzed 1,200 million tweets with 64 common emojis.|",9
"It was developed on social machines. And the idea behind this method is quite simple. So there's large-scale data behind this and deep learning. So basically, they took 1,200 million tweets containing emojis. So they selected the most common, the 64 most common emojis, and they were collecting a huge amount of tweets that contained these emojis.|","Made using social machines. The method is simple: big data and deep learning were applied to analyze 1,200 million tweets with 64 common emojis.|",1
And they formulated the following problem.,They identified a problem.,9
"So taking as an input the text, we want to predict the emoji of this text.",They want to predict emoji from text input.,8
"And when, so they have a deep learning architecture, you can actually, the code is available and they have also a demo online.",They have a deep learning model with code and an online demo.,7
So this is a screen capture of the demo.,This shows a demo screenshot.,7
"So if you enter the text I showed you before, you'll see this type of output.",Enter the text to see the output.,8
And they formulated the following problem.,They defined the problem.,8
"So taking as an input the text, we want to predict the emoji of this text.",They aim to predict emojis from text input.,7
"And when, so they have a deep learning architecture, you can actually, the code is available and they have also a demo online.",They use a deep learning model; code and demo are online.,6
So this is a screen capture of the demo.,Here is a screenshot of the demo.,7
"So if you enter the text I showed you before, you'll see this type of output.",You'll see output if you enter the text.,7
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|","This shows predicted emojis from the text. What is interesting is the varying word intensities due to the deep learning model's attention layer, capturing each word's contribution to the prediction. This demo is cool as you can cross out words and see how the emojis change.|",9
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|",Predicted emojis come from the text. The attention layer in the deep learning model shows varying word intensities. It captures the contributions of different words. The demo is cool because you can see how emojis change when you delete words.|,8
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|",Emojis are predicted from the text. Word intensities differ due to the model's attention layer. This captures the words' contributions. The demo shows how emojis change when words are removed.|,7
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|",Predicted emojis come from the text. The attention layer in a deep learning model shows word intensity differences and captures contributions. The demo lets you see how emojis change when words are crossed out.|,6
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|",Emojis are predicted from the text. The attention layer shows different word intensities and captures their contributions. This demo lets you cross out words to see how that changes the emojis.|,5
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|","This demo shows predicted emojis from text. Different word intensities are due to the attention layer, which captures contributions. You can cross out words and see how the emojis change.|",4
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|",This demo predicts emojis from text. The deep learning model's attention layer shows different word intensities. See how emojis change when words are crossed out.|,3
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|",The demo predicts emojis from text. The model's attention layer captures word intensities. See emojis change when words are removed.|,2
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|",The demo predicts emojis from the text. The attention layer captures word intensities. Watch how emojis change when words are crossed out.|,1
"So this is the emojis that are predicted from the text. And what is interesting is that you see here different intensities of the words. This is because the deep learning model has an attention layer. So it can capture the contribution of the different words to this prediction. And actually, this demo is very cool, because you can cross the different words and see how the emojis change when you remove some words.|",The demo shows emoji predictions from text. The model captures word intensities. See emojis change when removing words.|,1
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"This is effective, and similar models also work well for tech sentiment analysis.|",9
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,It works well. Similar models also analyze tech sentiment well.|,8
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,This model performs well. Other similar models also perform well in analyzing tech sentiment.|,7
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,This model works quite well. There are other similar models that are effective for tech sentiment analysis too.|,6
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"This model functions effectively for tech sentiment analysis, as do other similar models.|",5
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,This model and similar others work effectively for sentiment analysis in technology.|,4
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"For tech sentiment analysis, this model and other similar ones demonstrate effective performance.|",3
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"This model, along with others of its kind, proves to be quite effective in analyzing technological sentiment.|",2
So this is working pretty well. And there are other models that are similar to this one that also work pretty well for tech sentiment analysis.|,"This model exhibits a high degree of efficiency for tech sentiment analysis, and similarly, other models exhibit comparable effectiveness.|",1
