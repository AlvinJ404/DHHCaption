original_sentence,summary,level
"This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about. This class is not going to be about applications. This class is going to be about technology and infrastructure.","The person disappeared from the internet and the world but created valuable technology that inspired widely. This class will cover technology, not applications.",3
"This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about. This class is not going to be about applications. This class is going to be about technology and infrastructure.","This innovator disappeared online but created technology worth billions, inspiring new solutions beyond payments. The class will focus on technology and infrastructure.",4
"This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about. This class is not going to be about applications. This class is going to be about technology and infrastructure.","This person disappeared online but created technology worth billions, inspiring solutions beyond payments. This class focuses on technology, not applications.",5
"This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about. This class is not going to be about applications. This class is going to be about technology and infrastructure.","They vanished but created valuable technology inspiring new solutions. This class covers technology, not applications.",8
"This person is basically virtually disappeared from the internet and from the world. But it's created something that has captured so many people's imaginations and has sort of, depending on how you measure it, created billions and billions of dollars of economic value and sort of inspired a lot of people to think about how to use this technology to solve a myriad of different problems, not just electronic payments. So cryptocurrencies and the technology behind them are inspiring people to think about how to bank the unbanked, add more auditability and traceability to our world, get rid of trusted intermediaries and institutions in certain situations, and basically solve every problem if you read about what blockchains can do on the internet. Now, that's not exactly what this class is about. This class is not going to be about applications. This class is going to be about technology and infrastructure.","They disappeared but created technology worth billions inspiring solutions. This class covers tech, not apps.",9
And these words are kind of have floating evolving meanings right now.,These terms currently have evolving meanings.,9
It came from a community of enthusiasts on the internet.,It originated from online enthusiasts.,7
And so it doesn't necessarily have the same basis and rigor that we might expect for most of our academic fields of study.,"Thus, it lacks the standard academic rigor.",6
It's totally OK. We're figuring it out as we go along.,It's fine; we are learning as we go.,8
And these words are kind of have floating evolving meanings right now.,These terms have changing meanings currently.,6
It came from a community of enthusiasts on the internet.,It was developed by internet enthusiasts.,6
And academia is really embracing this topic.,Academia widely accepts this topic.,9
So there's huge opportunity here.,There is a large opportunity here.,8
And academia is really embracing this topic.,The academic world embraces this topic widely.,7
There's something different.,They are something different.,9
There's huge opportunity here.,There is significant opportunity available.,6
So there's huge opportunity here.,"Thus, there are major opportunities.",5
"And I'm going to start by showing you this picture because I want to highlight how remarkable is our ability to recognize emotions, our human ability to recognize emotions.",I'll begin by showing you a picture to highlight our remarkable ability to recognize emotions.,3
"So when you look at this image, for instance, we don't know anything about these people, but we can capture a lot of things about the atmosphere, right?","When we see this image, we may not know the people, but we can sense the atmosphere.",4
We see like a positive atmosphere and these people seem to be engaged and seem to be connecting on something.,We see a positive atmosphere and people engaged and connecting.,5
All of that is emotional information that we can capture just with one image.,All this emotional info is captured with one image.,6
And what does it mean to create a crypto?,What does it mean to create crypto?,8
We have this remarkable capacity for recognizing emotions.,We can recognize emotions well.,9
Why is this capacity useful for us?,Why is this skill useful?,8
It's very important in our social interactions.,It matters a lot in our social life.,7
"When we interact with people, we are constantly making guesses about how others feel in order to adapt the way we communicate to others' emotions.",We guess others' feelings to adapt our communication when interacting with people.,6
"It's very important to detect people's needs as well, and also to predict people's reactions.",Detecting people's needs and predicting reactions are vital.,5
And actually emotions are so important in our lives and have a strong influence in a lot of our cognitive processes.,Emotions greatly impact our lives and cognitive functions.,4
We have this remarkable capacity for recognizing emotions.,Recognizing emotions is an outstanding ability we possess.,3
It's very important in our social interactions.,"In social interactions, its importance is indisputable.",2
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Our attention, memory, and learning are affected by emotions. AI of the future is envisioned to have emotional intelligence, seen in many movies. Emotions are complex.",9
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Emotions impact attention, memory, and learning. AI is predicted to have emotional intelligence, as often shown in movies. Emotions remain complex.",8
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Emotions play a crucial role in attention, memory, and learning. Future AI with emotional intelligence is often depicted in movies. Emotions are complex.",7
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Emotions affect attention, memory, and learning processes. Future AI is expected to have emotions, as shown in movies. Emotions are complicated.",6
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Emotions modulate attention and affect memory and learning. Future AI is envisioned to have emotional intelligence, as seen in movies. Emotions are complex.",5
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Emotions influence memory, attention, and learning. Future AI may have emotional intelligence, as seen in movies. Emotions are intricate.",4
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Emotions affect attention mechanisms, memory, and learning. Future AI, often shown in movies, will have emotional intelligence. Emotions are complex.",3
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Emotions modulate our attention, influencing memory and learning. AI of the future, shown in movies, will have emotional intelligence. Emotions are complex.",2
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Emotions modulate our attention mechanisms and influence memory and learning. Future AI, shown in many movies, is expected to have emotional intelligence. Meanwhile, emotions are very complex.",1
"So for instance, they modulate our attention mechanisms and they strongly influence our memory and also our learning process. So emotions are so important in our lives. We imagine the AI of the future, so I'm going to ask how many of you have seen at least one of these movies here? So most of you have seen at least one of these movies. So you know what I said, I'm not going to make any spoiler, but you know what I'm saying when I say that the machines that we imagine in the future, all of them have some kind of emotional intelligence. But on the other side, emotions are so complex, right?","Emotions modulate attention and influence both memory and learning processes. AI of the future, often depicted in films, is imagined to possess emotional intelligence. Emotions are highly complex.",1
"Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel. So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures.","It's not easy to understand others' feelings. We can know some emotional states, but it's often difficult to understand both others and ourselves. How can machines handle this? Emotions change many things in our body. For example, nervousness raises heart rate and respiration, and changes in sweating, facial expressions, gaze, pupils, blood pressure, and posture occur.",1
"Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel. So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures.","Even people find understanding feelings hard. We get some emotional clues but often fail to know how others or we feel. So, how can machines grasp this? Emotions trigger many bodily changes. For example, nervousness alters heart rate, breathing, sweating, facial expressions, gaze, pupils, blood pressure, and posture.",2
"Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel. So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures.","Understanding how others feel is hard. We get some clues about emotions but often can't tell feelings. How can machines do it? Emotions change many body aspects, like heart rate, breathing, sweating, facial expressions, gaze, pupils, blood pressure, and posture.",3
"Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel. So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures.","It's hard to understand how others feel. We can get some emotional clues, but it's complex. How can machines handle this? When emotions change, our body shows many signs, like heart rate, breathing, sweating, facial expressions, gaze, pupils, blood pressure, and posture.",5
"Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel. So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures.","It's often hard for us to understand emotions. We can get some emotional information, but it's complex. How can machines do this? When emotions change, our body shows many signs like heart and respiratory rate, sweating, facial expressions, gaze, pupils, blood pressure, and posture.",6
"Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel. So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures.","It's hard for us to know others' feelings. We can get some emotional hints, but it's tricky. How can machines manage this? Emotional changes affect our body: heart rate, breathing, sweating, facial expressions, gaze, pupils, blood pressure, and posture all change.",7
"Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel. So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures.","It's tough to understand how others feel. Some emotional clues, but it's complex. How do machines do it? Emotions change body signals: heart, breathing, sweat, facial expressions, gaze, pupils, blood pressure, and posture all shift.",8
"Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel. So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures.","It's hard to know feelings. Emotional clues exist, but it's tricky. How do machines manage it? Emotions change body signals: heart, breathing, sweat, facial expressions, gaze, pupils, blood pressure, and posture shift.",9
"Even for us sometimes it's difficult to know how others feel. We can grasp some information about the upper and emotional states of people, but it's complex sometimes to know how others feel or even how we feel. So how can machines do something that complex? Well, the thing is that when our emotions change, there are a lot of things that change in our body. So for instance, when we are nervous, usually our heart rate increases, also our respiration rate increases, we sweat, so the electrodermal activity in our skin also changes. Our facial expression changes, our gaze patterns change, our pupil changes as well, our blood pressure, and we have different body postures.","Knowing feelings is hard. Emotional clues are tricky. How do machines manage them? Emotions change body signals: heart, breathing, sweat, facial expressions, gaze, pupils, blood pressure, and posture shift.",1
"We use different gestures depending on how we feel. Our voice can change as well, the way we write, the way we type in our phones, for instance. So there are a lot of signals that change with our emotions. So what we can do is all of these signals can be captured with different types of sensors. And then we capture these signals, and if we have data, label data with emotions, What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information. The same way we process other type of information.","Gestures vary with emotions. Voice, writing, and typing patterns change. Sensors capture these signals. Labeled data helps find emotion patterns, enabling algorithms to detect emotions.",9
"We use different gestures depending on how we feel. Our voice can change as well, the way we write, the way we type in our phones, for instance. So there are a lot of signals that change with our emotions. So what we can do is all of these signals can be captured with different types of sensors. And then we capture these signals, and if we have data, label data with emotions, What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information. The same way we process other type of information.","Emotions alter gestures, voice, writing, and typing. Sensors capture these signals, and labeled data aids in identifying patterns for emotion detection algorithms.",8
"We use different gestures depending on how we feel. Our voice can change as well, the way we write, the way we type in our phones, for instance. So there are a lot of signals that change with our emotions. So what we can do is all of these signals can be captured with different types of sensors. And then we capture these signals, and if we have data, label data with emotions, What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information. The same way we process other type of information.","We show emotions in gestures, voice, and writing. Sensors can capture these signals and labeled data helps detect emotion patterns for algorithms.",7
"We use different gestures depending on how we feel. Our voice can change as well, the way we write, the way we type in our phones, for instance. So there are a lot of signals that change with our emotions. So what we can do is all of these signals can be captured with different types of sensors. And then we capture these signals, and if we have data, label data with emotions, What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information. The same way we process other type of information.","Gestures, voice, and writing show how we feel. Sensors capture these signals. Labeled data finds emotion patterns, aiding detection by algorithms.",6
"We use different gestures depending on how we feel. Our voice can change as well, the way we write, the way we type in our phones, for instance. So there are a lot of signals that change with our emotions. So what we can do is all of these signals can be captured with different types of sensors. And then we capture these signals, and if we have data, label data with emotions, What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information. The same way we process other type of information.","Emotions change our gestures, voice, and writing. Sensors capture these signals. Labeled data helps find emotion patterns, and algorithms detect these emotions.",5
"We use different gestures depending on how we feel. Our voice can change as well, the way we write, the way we type in our phones, for instance. So there are a lot of signals that change with our emotions. So what we can do is all of these signals can be captured with different types of sensors. And then we capture these signals, and if we have data, label data with emotions, What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information. The same way we process other type of information.","Our gestures, voice, and writing change with emotions. These signals are captured by sensors. Labeled data is used to find patterns, enabling algorithms to detect emotions.",4
"We use different gestures depending on how we feel. Our voice can change as well, the way we write, the way we type in our phones, for instance. So there are a lot of signals that change with our emotions. So what we can do is all of these signals can be captured with different types of sensors. And then we capture these signals, and if we have data, label data with emotions, What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information. The same way we process other type of information.","Our emotions alter gestures, voice, and writing styles. Sensors can capture these signals, and the labeled data allows patterns to be found that help develop algorithms for emotion recognition.",3
"We use different gestures depending on how we feel. Our voice can change as well, the way we write, the way we type in our phones, for instance. So there are a lot of signals that change with our emotions. So what we can do is all of these signals can be captured with different types of sensors. And then we capture these signals, and if we have data, label data with emotions, What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information. The same way we process other type of information.","Various gestures, voice tones, and writing styles vary based on emotions. Sensors can capture these changes. When signals are labeled with their respective emotions, patterns can be identified, allowing development of algorithms that recognize emotions.",2
"We use different gestures depending on how we feel. Our voice can change as well, the way we write, the way we type in our phones, for instance. So there are a lot of signals that change with our emotions. So what we can do is all of these signals can be captured with different types of sensors. And then we capture these signals, and if we have data, label data with emotions, What we can do is we can try to find patterns in these signals that correlate with emotions and develop machine learning algorithms or systems that can recognize the emotions using this type of information. The same way we process other type of information.","Gestures, voice pitch, and writing habits shift with emotional state. By capturing these signals with sensors, labeled emotional data aids in discovering correlating patterns, facilitating the creation of machine learning algorithms to identify emotions.",1
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|","I will discuss capturing emotional data, starting with vision modality which is my expertise. What research exists in recognizing emotions through cameras? Any idea on popular techniques?|",1
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|","I will discuss emotional data, starting with cameras. What techniques are used to recognize emotions through cameras?|",2
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|",I will discuss capturing emotions through cameras. Which research is popular for this in computer vision?|,3
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|",Let's discuss capturing emotions using cameras. What popular computer vision research exists on this?|,4
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|",Let's explore how cameras capture emotions. What known computer vision techniques achieve this?|,5
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|",How do cameras detect emotions? Which computer vision research is popular in this field?|,6
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|",How do cameras capture emotions? Which research in computer vision is most popular?|,7
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|",How do cameras read emotions? What's the top research on this in computer vision?|,8
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|",How do cameras read emotions? What's the leading research on this in computer vision?|,9
"I'm going to focus first on the, so I'm going to talk about some examples of how can we capture this emotional information. And I'm going to start with vision modality, which is one of my areas of expertise. So visual modality, cameras. What has been done so far for recognizing emotions from information captured by cameras? Any idea? What's the most popular research from a computer vision perspective to recognize emotions?|",How do cameras read feelings? What's the leading research on this in computer vision?|,1
"This software works very well, so it's very well at detecting the patterns, it's very while detecting the key points, it's complicated to associate the correct emotion to an expression, a phase expression, but it works pretty well in some applications.","The software works well at detecting patterns and key points, but associating emotions to expressions is complicated. It works in some applications.",9
So we would like to have machines that can recognize emotions in any condition.,We want machines to recognize emotions in any condition.,9
"I don't know exactly how this detection of attention works here, but actually it's pretty accurate.","The detection of attention is unclear, but it is accurate.",9
"This software works very well, so it's very well at detecting the patterns, it's very while detecting the key points, it's complicated to associate the correct emotion to an expression, a phase expression, but it works pretty well in some applications.",The software efficiently detects patterns and key points but struggles with emotions in expressions.,5
"It's being used for test users, for instance, but the problem of this software is that it does not work in the wild.","The software is used by test users, but it fails in natural conditions.",5
So we would like to have machines that can recognize emotions in any condition.,We want machines that recognize emotions in any situation.,7
"So, if we go back to this image that I showed you before, what happens when we run this type of software here?","Refer to the image shown earlier, what results from running this software?",5
"But what happens with him? So what happens with him is that the system is not working. So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like.|","Glasses and profile views hide facial points, causing system failure.|",6
"But what happens with him? So what happens with him is that the system is not working. So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like.|",System fails due to glasses and profile views.|,7
"But what happens with him? So what happens with him is that the system is not working. So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like.|",Glasses and profile views cause system errors.|,8
"But what happens with him? So what happens with him is that the system is not working. So here we have a problem and it's all the key points of the face are not actually visible. So we have strong occlusions and highlights because of the glasses of the person. And also we have a profile view, so it's not a frontal view anymore where everything is visible, right? So this type of software, when you run them in open environments, you face that when you have nonfrontal faces and partial occlusions, they might not work as well as we would like.|",System fails.|,9
"More problems. So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.|","Another problem arises with a face example. Running the software shows surprise with an open mouth, detecting surprise perfectly.",1
"More problems. So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.|",Another example of problems: the software detects a face's surprise with perfect accuracy.,2
"More problems. So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.|","There are more problems, like this face example. The software detects an open mouth indicating surprise correctly.",3
"More problems. So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.|",Another example shows a face. The software identifies the surprise shown by an open mouth accurately.,4
"More problems. So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.|",We meet another problem: a face example. The software perfectly detects the surprise with the mouth open.,5
"More problems. So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.|","One more example: a face. The software detects surprise accurately, observing an open mouth.",7
"More problems. So here we have another example. Here is a face. If we run the software, it says, you see surprise. The mouth is open. So it's detecting perfectly well a very prototypical expression of surprise.|",The software detects surprise in a face accurately. The mouth is open.,9
"But when we look at the context, we realize that it's not surprise, right?",Examining context shows it's not surprising.,9
"So the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing.","This face shows the action, not emotion.",7
So some of our facial expressions have nothing to do with our emotions but with other things.,Some expressions aren't linked to emotions.,6
"For instance, when you talk, you change a lot your facial expression.",Talking changes your facial expressions.,8
"ut when we look at the context, we realize that it's not surprise, right?",Context shows it's not surprising.,7
"o the thing is that this kit, we see a facial expression here but has nothing to do with the emotion, it's related to the action he is performing.","The face shows action, not emotion.",8
o some of our facial expressions have nothing to do with our emotions but with other things.,"Some faces show actions, not feeling.",4
"or instance, when you talk, you change a lot your facial expression.",Talking changes your facial movements.,7
"So I'm going to show you some examples of experiments that were performed by psychologists that were studying what's the level of agreement in giving an emotional label to a specific facial expression, like here.",Let me show you some experiments by psychologists studying agreement on labeling emotions to facial expressions.,9
"So here we see clearly a facial expression, but if I ask you, what's this facial expression communicating? Well, you might think maybe anger, maybe contempt, this gas fear.","We see a facial expression; you might guess it indicates anger, contempt, or fear.",8
"So usually people agree that this is a negative, valence emotion, but it's not clear what category.","People agree this expression shows a negative emotion, but the category is unclear.",7
"The thing is that if I give you some context suddenly, we probably will agree that this is disgust and this is what happens.","Given context, we likely agree the face shows disgust.",6
People agree here that the face is disgust.,Everyone agrees the face shows disgust.,9
"But if you give you a different context, then people strongly agree that this is anger. So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts. And they realize that the context strongly influences the way we perceive emotions. So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face. We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person. And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.","In different contexts, the same facial expression can indicate anger. Examples and experiments show context influences emotion perception. This project started in Barcelona and continues with MIT. Machines must consider the context to recognize emotions accurately. Collaborators study scene context to better understand emotions.",9
"But if you give you a different context, then people strongly agree that this is anger. So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts. And they realize that the context strongly influences the way we perceive emotions. So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face. We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person. And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.","The emotion perceived can change with context, even if the facial expression is the same. This inspired a project in Barcelona, now continuing with MIT, to create machines that look at the context to read emotions. They especially focus on the scene context.",8
"But if you give you a different context, then people strongly agree that this is anger. So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts. And they realize that the context strongly influences the way we perceive emotions. So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face. We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person. And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.","Same facial expression means anger in another context. Researchers use examples and experiments showing context determines emotion perception. This motivated a project from Barcelona to MIT, aiming to make machines recognize emotions by understanding context, especially scene context.",7
"But if you give you a different context, then people strongly agree that this is anger. So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts. And they realize that the context strongly influences the way we perceive emotions. So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face. We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person. And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.","The way emotions are perceived changes with context. Experimenting with the same facial expression in different situations shows this. This inspired a project, now involving MIT, aiming to develop machines that recognize emotions by also considering context.",6
"But if you give you a different context, then people strongly agree that this is anger. So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts. And they realize that the context strongly influences the way we perceive emotions. So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face. We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person. And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.","Experiments show that context affects how we perceive the same facial expressions. This motivated a project that started in Barcelona and now involves MIT. The goal is to make machines that understand emotional context, focusing on scene context.",5
"But if you give you a different context, then people strongly agree that this is anger. So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts. And they realize that the context strongly influences the way we perceive emotions. So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face. We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person. And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.","Research shows context can change our perception of the same facial expression. This led to a project involving MIT, aiming to develop machines that understand emotions through context.",4
"But if you give you a different context, then people strongly agree that this is anger. So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts. And they realize that the context strongly influences the way we perceive emotions. So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face. We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person. And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.","Context changes emotion perception, as shown through experiments. This inspired a project, now involving MIT, to help machines read emotions by considering context.",3
"But if you give you a different context, then people strongly agree that this is anger. So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts. And they realize that the context strongly influences the way we perceive emotions. So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face. We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person. And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.","Context affects how we see emotions in faces. This started a project with MIT to help machines read emotions by looking at context, especially scene context.",2
"But if you give you a different context, then people strongly agree that this is anger. So they have a lot of examples and they run a lot of experiments in using the exact same facial expression in different contexts. And they realize that the context strongly influences the way we perceive emotions. So this is the motivation of one of the projects I'm working on that started here in Barcelona and now I'm still working on it in collaboration with the effective computing group at MIT media lab and the idea behind this project is okay, we know there's a lot of information in the face, that's true, but for developing machines that accurately recognize emotions, we can just rely on the face. We need to understand the context of the person and in particularly we are working in the scene context, in the situation of the person. And the interesting thing of working in this type of context is that suddenly you can say much more about the emotion.",Context changes how we see emotions in faces. A project with MIT was created to help machines understand this. Focus is on scene context.,1
"So maybe with the expression, you can say something about basic emotions, but there are some secondary emotions or social emotions that are very interesting that if you don't see the context, you cannot say anything about them.","Facial expressions can show basic emotions, but for complex emotions, context is essential.",1
"Like here, once you see the context, you might say that this person is feeling confident.",Context reveals that this person is feeling confident.,2
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud.",Confidence is the feeling of certainty and belief in a favorable outcome.,3
So that's the idea of the emotion recognition in context project.,This is the aim of the emotion recognition in context project.,4
"So what we want to do is we want to go from images like this one, so not just relating on the face and looking also at the context of the person, trying to recognize emotions, and for that, so this is a computer vision project.",We aim to recognize emotions from facial images and context using a computer vision project.,5
We know that in computer vision nowadays what is working best is deep learning models.,Deep learning models are currently the best in computer vision.,6
"So maybe with the expression, you can say something about basic emotions, but there are some secondary emotions or social emotions that are very interesting that if you don't see the context, you cannot say anything about them.","Expressions show basic emotions, but without context, complex emotions are hard to identify.",7
"Like here, once you see the context, you might say that this person is feeling confident.",Context shows this person is confident.,8
"When you define confidence as feeling of being certain, conviction that an outcome will be favorable, encouraged, or proud.",Confidence means feeling certain and believing in a good outcome.,9
So that's the idea of the emotion recognition in context project.,This is the emotion recognition in context project.,1
We had two different interfaces.,We used two interfaces.,9
This is the one of emotion categories.,This one is for emotion categories.,7
And we have another one for continuous dimensions.,We have another for continuous dimensions.,7
So there are different ways of representing emotions in a machine.,Machines can represent emotions in different ways.,6
Categories is one of the most common and emotional dimensions is the other one.,Categories and dimensions are common emotion representations.,5
We had two different interfaces.,We had two different interfaces for labeling.,2
This is the one of emotion categories.,This is the interface for emotion categories.,3
And we have another one for continuous dimensions.,We have another interface for continuous dimensions.,5
Maybe it's less popular.,It might be less known.,9
"But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative.","The continuous dimensions label emotions by valence, measuring if feelings are positive or negative.",4
"A rousal is measuring whether someone is in calm or very ready to act, very agitated.",Arousal measures if someone is calm or very agitated.,6
And then dominance that is measuring whether someone is feeling dominated by the situation or the opposite is that someone is feeling in control of the situation.,Dominance measures if someone feels dominated or in control.,5
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age.","We also collected the person's demographics, like gender and age.",5
Maybe it's less popular.,Maybe it's less popular.,9
"But the idea of the continuous dimensions is to label according to valence, which is is a dimension that just measures whether someone is feeling something positive or something negative.",Valence measures whether feelings are positive or negative.,5
"A rousal is measuring whether someone is in calm or very ready to act, very agitated.",Arousal measures if someone is calm or agitated.,6
"And then we also collected some demographics of the person in the picture, like the gender or the estimated age.",We gathered demographics like gender and age.,6
"So basically, we have as input the image, and we know the location of the target person that we are trying to recognize the emotion of.",We input the image and pinpoint the target person's location for emotion recognition.,9
And then we have one module that is extracting person features.,"Then, a module extracts features of the person.",8
And then we merge these features.,"Then, we combine these features.",9
We have one fully connected layer.,We use a fully connected layer.,9
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","We separate recognition of balance, land dominance, and emotion categories, using regression as the loss function. From our experiments, we found it the best way to model data. We get these types of results and images, recognizing anticipation, excitement, engagement, and confidence in one case. Another example shows recognition of pleasure, happiness, and affection.",1
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","We use regression to model data for recognizing balance, land dominance, and different emotions. Our experiments showed it's the best method. We get results like anticipation, excitement, engagement, and confidence in one image and pleasure, happiness, and affection in another.",2
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","We use regression to model data for recognizing balance, land dominance, and emotions. Our experiments found it most effective. Results include recognizing anticipation, excitement, engagement, and confidence, plus pleasure, happiness, and affection.",3
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","We identify balance, land dominance, and emotions using regression after experiments proved it best. We recognize anticipation, excitement, engagement, confidence, pleasure, happiness, and affection in images.",4
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","For balance, land dominance, and emotions, we use regression, the best method from experiments. Results include recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.",5
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","For recognizing balance, land dominance, and emotions, we use regression, found best from experiments. We get results like anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.",6
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","We use regression to recognize balance, land dominance, and emotions, shown best by experiments. Results include recognizing anticipation, excitement, engagement, confidence, pleasure, happiness, and affection.",7
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","We use regression for recognizing balance, land dominance, and emotions using regression, best by our experiments. Our results include anticipation, excitement, engagement, confidence, happiness, and affection.",8
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","We use regression for recognizing balance, land dominance, and emotions. Experiments showed it's best. Results include anticipation, excitement, confidence, happiness, and affection in images.",9
"And we separate the recognition of balance, and also land dominance, and the emotion categories. And the type of loss function that we use is regression, because from our experiments, we saw that it was the best way to model our data. So these are the type of results that we get. So these are the type of images that we get. This is recognition of anticipation, excitement, engagement, and confidence in this case. This is another example of recognition, pleasure, happiness, and affection in this other picture.","We use regression to identify balance, land dominance, and emotions. The experiments showed this is best. Results include recognizing anticipation, excitement, confidence, and happiness in pictures.",1
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation. Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output. So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context. So this is our first baseline. We are progressing this project in different directions.","The system could identify happiness without seeing the face, using context. In another case, it detected various emotions, using context and the person. The system is not very reliable yet. This is a first attempt to use context and person to recognize emotions. The project continues.",2
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation. Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output. So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context. So this is our first baseline. We are progressing this project in different directions.","The system recognized happiness without seeing the face, implying it uses context. In another case, it identified various emotions, combining context and the person. However, the system is not very effective yet. This is its first attempt to use both context and person for emotion recognition, and the project is ongoing.",3
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation. Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output. So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context. So this is our first baseline. We are progressing this project in different directions.","The system recognized happiness without seeing the face, hinting it uses context. It identified various emotions using both context and the person. The system is not very effective yet. This is its first attempt to combine context and person for emotion recognition. The project is ongoing.",4
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation. Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output. So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context. So this is our first baseline. We are progressing this project in different directions.","The system recognized happiness without seeing the face, indicating it uses context. In another instance, it identified various emotions using context and the person, but it is not very effective yet. This is its first attempt combining context and person for emotion recognition and the project is developing.",5
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation. Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output. So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context. So this is our first baseline. We are progressing this project in different directions.","The system recognized happiness without seeing the face, so it uses context. Another case showed it identifies many emotions using both context and person. The system is not very effective yet. This is its first attempt at combining context and person for emotion recognition, and the project is developing.",6
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation. Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output. So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context. So this is our first baseline. We are progressing this project in different directions.","The system recognized happiness without seeing the face, hinting it uses context. Another case showed it can detect emotions by combining context and person. The system still needs improvement. This is its first attempt at using context and person for emotions, and the project continues.",7
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation. Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output. So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context. So this is our first baseline. We are progressing this project in different directions.","The system recognized happiness without seeing the face, indicating it uses context. Another case showed it can detect emotions by combining context and person. The system needs improvement. This is its first attempt at using context and person for emotions. The project continues.",8
"Another one pretty challenging that here is, it recognized happiness, the system, but here you don't see the face. So clearly somehow it's extracting some information about the context and the situation. Here another interesting example where for this guy, and the recognition of emotions was like pleasure, affection and happiness, but for the other person, it was like a mess, so it recognized almost everything possible, and so this is showing that not all the information is coming just from the context, but it's the combination of the context and the person which actually creates the output. So the truth is that this system is not working very well, so this is the first attempt in trying to recognize emotions using not just face, but using person and situational context. So this is our first baseline. We are progressing this project in different directions.","The system recognized happiness without seeing the face, so it uses context. Another case showed it can detect emotions by combining context and person. The system still needs work. This is its first attempt at using context and person for emotions, and the project continues.",9
"So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review. review. So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.","The Red House in Cambridge, MA, has great reviews. If you check online, one review mentions a delightful spot with a terrific menu, craft cocktails, and a relaxed vibe with locals and college professors.",2
"So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review. review. So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.","The Red House in Cambridge has good reviews. One review mentions a great menu, craft cocktails, and a friendly atmosphere with locals and professors.",4
"So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review. review. So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.","The Red House in Cambridge has a positive review. It praises the menu, cocktails, and a relaxed atmosphere with locals and professors.",6
"So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review. review. So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.","The Red House in Cambridge gets good reviews. One says it has a great menu, cocktails, and a friendly atmosphere with locals and professors.",7
"So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review. review. So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.","The Red House has good reviews. One praises the menu, cocktails, and the friendly atmosphere.",8
"So the Red House restaurant is a restaurant in Cambridge, Massachusetts in USA. So if you go to this restaurant and you never went to this restaurant and you want to know how this restaurant works, so you Google this restaurant and you get all of these reviews. So this is one example of a review of the Red House restaurant. Okay, so let's focus in a piece of this review. review. So here it says, what's a delight, terrific menu, great craft, cocktails, unpretentious atmosphere of mostly locals and college professors chatting over dinner.","The Red House has great reviews. It is praised for its menu, cocktails, and friendly vibe.",9
